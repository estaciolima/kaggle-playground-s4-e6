{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset reference: https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success\n",
    "- Competition site: https://www.kaggle.com/competitions/playground-series-s4e6/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Marital status  Application mode  Application order  Course  \\\n",
       "id                                                                \n",
       "0                1                 1                  1    9238   \n",
       "1                1                17                  1    9238   \n",
       "2                1                17                  2    9254   \n",
       "3                1                 1                  3    9500   \n",
       "4                1                 1                  2    9500   \n",
       "\n",
       "    Daytime/evening attendance  Previous qualification  \\\n",
       "id                                                       \n",
       "0                            1                       1   \n",
       "1                            1                       1   \n",
       "2                            1                       1   \n",
       "3                            1                       1   \n",
       "4                            1                       1   \n",
       "\n",
       "    Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "id                                                                        \n",
       "0                            126.0            1                       1   \n",
       "1                            125.0            1                      19   \n",
       "2                            137.0            1                       3   \n",
       "3                            131.0            1                      19   \n",
       "4                            132.0            1                      19   \n",
       "\n",
       "    Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "id                          ...                                        \n",
       "0                       19  ...                                    0   \n",
       "1                       19  ...                                    0   \n",
       "2                       19  ...                                    0   \n",
       "3                        3  ...                                    0   \n",
       "4                       37  ...                                    0   \n",
       "\n",
       "    Curricular units 2nd sem (enrolled)  \\\n",
       "id                                        \n",
       "0                                     6   \n",
       "1                                     6   \n",
       "2                                     6   \n",
       "3                                     8   \n",
       "4                                     7   \n",
       "\n",
       "    Curricular units 2nd sem (evaluations)  \\\n",
       "id                                           \n",
       "0                                        7   \n",
       "1                                        9   \n",
       "2                                        0   \n",
       "3                                       11   \n",
       "4                                       12   \n",
       "\n",
       "    Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "id                                                                          \n",
       "0                                     6                         12.428571   \n",
       "1                                     0                          0.000000   \n",
       "2                                     0                          0.000000   \n",
       "3                                     7                         12.820000   \n",
       "4                                     6                         12.933333   \n",
       "\n",
       "    Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "id                                                                      \n",
       "0                                                0               11.1   \n",
       "1                                                0               11.1   \n",
       "2                                                0               16.2   \n",
       "3                                                0               11.1   \n",
       "4                                                0                7.6   \n",
       "\n",
       "    Inflation rate   GDP    Target  \n",
       "id                                  \n",
       "0              0.6  2.02  Graduate  \n",
       "1              0.6  2.02   Dropout  \n",
       "2              0.3 -0.92   Dropout  \n",
       "3              0.6  2.02  Enrolled  \n",
       "4              2.6  0.32  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/train.csv', index_col='id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 1st sem (without evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Marital status  Application mode  Application order  Course  \\\n",
       "id                                                                \n",
       "0                1                 1                  1    9238   \n",
       "1                1                17                  1    9238   \n",
       "2                1                17                  2    9254   \n",
       "3                1                 1                  3    9500   \n",
       "4                1                 1                  2    9500   \n",
       "\n",
       "    Daytime/evening attendance  Previous qualification  \\\n",
       "id                                                       \n",
       "0                            1                       1   \n",
       "1                            1                       1   \n",
       "2                            1                       1   \n",
       "3                            1                       1   \n",
       "4                            1                       1   \n",
       "\n",
       "    Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "id                                                                        \n",
       "0                            126.0            1                       1   \n",
       "1                            125.0            1                      19   \n",
       "2                            137.0            1                       3   \n",
       "3                            131.0            1                      19   \n",
       "4                            132.0            1                      19   \n",
       "\n",
       "    Father's qualification  ...  \\\n",
       "id                          ...   \n",
       "0                       19  ...   \n",
       "1                       19  ...   \n",
       "2                       19  ...   \n",
       "3                        3  ...   \n",
       "4                       37  ...   \n",
       "\n",
       "    Curricular units 1st sem (without evaluations)  \\\n",
       "id                                                   \n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "\n",
       "    Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       "id                                                                             \n",
       "0                                     0                                    6   \n",
       "1                                     0                                    6   \n",
       "2                                     0                                    6   \n",
       "3                                     0                                    8   \n",
       "4                                     0                                    7   \n",
       "\n",
       "    Curricular units 2nd sem (evaluations)  \\\n",
       "id                                           \n",
       "0                                        7   \n",
       "1                                        9   \n",
       "2                                        0   \n",
       "3                                       11   \n",
       "4                                       12   \n",
       "\n",
       "    Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "id                                                                          \n",
       "0                                     6                         12.428571   \n",
       "1                                     0                          0.000000   \n",
       "2                                     0                          0.000000   \n",
       "3                                     7                         12.820000   \n",
       "4                                     6                         12.933333   \n",
       "\n",
       "    Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "id                                                                      \n",
       "0                                                0               11.1   \n",
       "1                                                0               11.1   \n",
       "2                                                0               16.2   \n",
       "3                                                0               11.1   \n",
       "4                                                0                7.6   \n",
       "\n",
       "    Inflation rate   GDP  \n",
       "id                        \n",
       "0              0.6  2.02  \n",
       "1              0.6  2.02  \n",
       "2              0.3 -0.92  \n",
       "3              0.6  2.02  \n",
       "4              2.6  0.32  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Target']\n",
    "X = df.drop(['Target'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 76518 entries, 0 to 76517\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   Marital status                                  76518 non-null  int64  \n",
      " 1   Application mode                                76518 non-null  int64  \n",
      " 2   Application order                               76518 non-null  int64  \n",
      " 3   Course                                          76518 non-null  int64  \n",
      " 4   Daytime/evening attendance                      76518 non-null  int64  \n",
      " 5   Previous qualification                          76518 non-null  int64  \n",
      " 6   Previous qualification (grade)                  76518 non-null  float64\n",
      " 7   Nacionality                                     76518 non-null  int64  \n",
      " 8   Mother's qualification                          76518 non-null  int64  \n",
      " 9   Father's qualification                          76518 non-null  int64  \n",
      " 10  Mother's occupation                             76518 non-null  int64  \n",
      " 11  Father's occupation                             76518 non-null  int64  \n",
      " 12  Admission grade                                 76518 non-null  float64\n",
      " 13  Displaced                                       76518 non-null  int64  \n",
      " 14  Educational special needs                       76518 non-null  int64  \n",
      " 15  Debtor                                          76518 non-null  int64  \n",
      " 16  Tuition fees up to date                         76518 non-null  int64  \n",
      " 17  Gender                                          76518 non-null  int64  \n",
      " 18  Scholarship holder                              76518 non-null  int64  \n",
      " 19  Age at enrollment                               76518 non-null  int64  \n",
      " 20  International                                   76518 non-null  int64  \n",
      " 21  Curricular units 1st sem (credited)             76518 non-null  int64  \n",
      " 22  Curricular units 1st sem (enrolled)             76518 non-null  int64  \n",
      " 23  Curricular units 1st sem (evaluations)          76518 non-null  int64  \n",
      " 24  Curricular units 1st sem (approved)             76518 non-null  int64  \n",
      " 25  Curricular units 1st sem (grade)                76518 non-null  float64\n",
      " 26  Curricular units 1st sem (without evaluations)  76518 non-null  int64  \n",
      " 27  Curricular units 2nd sem (credited)             76518 non-null  int64  \n",
      " 28  Curricular units 2nd sem (enrolled)             76518 non-null  int64  \n",
      " 29  Curricular units 2nd sem (evaluations)          76518 non-null  int64  \n",
      " 30  Curricular units 2nd sem (approved)             76518 non-null  int64  \n",
      " 31  Curricular units 2nd sem (grade)                76518 non-null  float64\n",
      " 32  Curricular units 2nd sem (without evaluations)  76518 non-null  int64  \n",
      " 33  Unemployment rate                               76518 non-null  float64\n",
      " 34  Inflation rate                                  76518 non-null  float64\n",
      " 35  GDP                                             76518 non-null  float64\n",
      " 36  Target                                          76518 non-null  object \n",
      "dtypes: float64(7), int64(29), object(1)\n",
      "memory usage: 22.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores faltantes\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Marital status', 'Application mode', 'Application order', 'Course',\n",
       "       'Daytime/evening attendance', 'Previous qualification',\n",
       "       'Previous qualification (grade)', 'Nacionality',\n",
       "       'Mother's qualification', 'Father's qualification',\n",
       "       'Mother's occupation', 'Father's occupation', 'Admission grade',\n",
       "       'Displaced', 'Educational special needs', 'Debtor',\n",
       "       'Tuition fees up to date', 'Gender', 'Scholarship holder',\n",
       "       'Age at enrollment', 'International',\n",
       "       'Curricular units 1st sem (credited)',\n",
       "       'Curricular units 1st sem (enrolled)',\n",
       "       'Curricular units 1st sem (evaluations)',\n",
       "       'Curricular units 1st sem (approved)',\n",
       "       'Curricular units 1st sem (grade)',\n",
       "       'Curricular units 1st sem (without evaluations)',\n",
       "       'Curricular units 2nd sem (credited)',\n",
       "       'Curricular units 2nd sem (enrolled)',\n",
       "       'Curricular units 2nd sem (evaluations)',\n",
       "       'Curricular units 2nd sem (approved)',\n",
       "       'Curricular units 2nd sem (grade)',\n",
       "       'Curricular units 2nd sem (without evaluations)', 'Unemployment rate',\n",
       "       'Inflation rate', 'GDP', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76513</th>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76514</th>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76515</th>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76516</th>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76517</th>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76518 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target\n",
       "id             \n",
       "0      Graduate\n",
       "1       Dropout\n",
       "2       Dropout\n",
       "3      Enrolled\n",
       "4      Graduate\n",
       "...         ...\n",
       "76513  Graduate\n",
       "76514  Graduate\n",
       "76515  Enrolled\n",
       "76516   Dropout\n",
       "76517  Graduate\n",
       "\n",
       "[76518 rows x 1 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variáveis\n",
    "- Marital Status: numbers -> Transform into categorical var\n",
    "- Application mode: numbers -> Transform into categorical var\n",
    "- Course: numbers -> Transform into categorical var\n",
    "- Daytime/evening attendance -> transform into categorical var\n",
    "- Previous qualification -> transform into categorical var\n",
    "- previous qualification (grade) -> looks like numerical\n",
    "- Nacionality -> transform into categorical var\n",
    "- Mother's qualification -> transform into cat var\n",
    "- Father's qualification -> transform into cat var\n",
    "- Mother's occupation -> transform into cat var\n",
    "- Father's occupation -> transform into cat var\n",
    "- Addmission grade -> looks numericals\n",
    "- Displaced -> transform into binary var\n",
    "- Educational special needs -> binary var\n",
    "- Debtor -> binary var\n",
    "- Tuition fees up to date -> binary var\n",
    "- Gender -> binary var\n",
    "- Scholarship holder -> binary var\n",
    "- Age at enrollment -> numerical var (ok)\n",
    "- International -> binary var\n",
    "- Curricular units -> I'm not sure what this is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype('category')\n",
    "df = df.astype({'Previous qualification (grade)': 'float64',\n",
    "           'Admission grade': 'float64',\n",
    "           'Age at enrollment': 'int64',\n",
    "           'Curricular units 1st sem (credited)': 'int64',\n",
    "           'Curricular units 1st sem (enrolled)': 'int64',\n",
    "           'Curricular units 1st sem (evaluations)': 'int64',\n",
    "           'Curricular units 1st sem (approved)': 'int64',\n",
    "           'Curricular units 1st sem (grade)': 'float64',\n",
    "           'Curricular units 1st sem (without evaluations)': 'int64',\n",
    "           'Curricular units 2nd sem (credited)': 'int64',\n",
    "           'Curricular units 2nd sem (enrolled)': 'int64',\n",
    "           'Curricular units 2nd sem (evaluations)': 'int64',\n",
    "           'Curricular units 2nd sem (approved)': 'int64',\n",
    "           'Curricular units 2nd sem (grade)': 'float64',\n",
    "           'Curricular units 2nd sem (without evaluations)': 'int64',\n",
    "           'Unemployment rate': 'float64',\n",
    "           'Inflation rate': 'float64',\n",
    "           'GDP': 'float64'\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Marital status                                    category\n",
       "Application mode                                  category\n",
       "Application order                                 category\n",
       "Course                                            category\n",
       "Daytime/evening attendance                        category\n",
       "Previous qualification                            category\n",
       "Previous qualification (grade)                     float64\n",
       "Nacionality                                       category\n",
       "Mother's qualification                            category\n",
       "Father's qualification                            category\n",
       "Mother's occupation                               category\n",
       "Father's occupation                               category\n",
       "Admission grade                                    float64\n",
       "Displaced                                         category\n",
       "Educational special needs                         category\n",
       "Debtor                                            category\n",
       "Tuition fees up to date                           category\n",
       "Gender                                            category\n",
       "Scholarship holder                                category\n",
       "Age at enrollment                                    int64\n",
       "International                                     category\n",
       "Curricular units 1st sem (credited)                  int64\n",
       "Curricular units 1st sem (enrolled)                  int64\n",
       "Curricular units 1st sem (evaluations)               int64\n",
       "Curricular units 1st sem (approved)                  int64\n",
       "Curricular units 1st sem (grade)                   float64\n",
       "Curricular units 1st sem (without evaluations)       int64\n",
       "Curricular units 2nd sem (credited)                  int64\n",
       "Curricular units 2nd sem (enrolled)                  int64\n",
       "Curricular units 2nd sem (evaluations)               int64\n",
       "Curricular units 2nd sem (approved)                  int64\n",
       "Curricular units 2nd sem (grade)                   float64\n",
       "Curricular units 2nd sem (without evaluations)       int64\n",
       "Unemployment rate                                  float64\n",
       "Inflation rate                                     float64\n",
       "GDP                                                float64\n",
       "Target                                            category\n",
       "dtype: object"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Target', ylabel='count'>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_variables = df.drop('Target', axis=1).select_dtypes(include='category').columns.to_list()\n",
    "num_variables = df.select_dtypes(include=['int64', 'float64']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_variables),\n",
    "    ('num', StandardScaler(), num_variables)\n",
    "])\n",
    "\n",
    "X_trans = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<76518x280 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2085077 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ct.named_transformers_['cat'].get_feature_names_out().tolist()+ct.named_transformers_['num'].get_feature_names_out().tolist()\n",
    "X_trans = pd.DataFrame.sparse.from_spmatrix(X_trans, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Marital status_2',\n",
       " 'Marital status_3',\n",
       " 'Marital status_4',\n",
       " 'Marital status_5',\n",
       " 'Marital status_6',\n",
       " 'Application mode_2',\n",
       " 'Application mode_3',\n",
       " 'Application mode_4',\n",
       " 'Application mode_5',\n",
       " 'Application mode_7',\n",
       " 'Application mode_9',\n",
       " 'Application mode_10',\n",
       " 'Application mode_12',\n",
       " 'Application mode_15',\n",
       " 'Application mode_16',\n",
       " 'Application mode_17',\n",
       " 'Application mode_18',\n",
       " 'Application mode_26',\n",
       " 'Application mode_27',\n",
       " 'Application mode_35',\n",
       " 'Application mode_39',\n",
       " 'Application mode_42',\n",
       " 'Application mode_43',\n",
       " 'Application mode_44',\n",
       " 'Application mode_51',\n",
       " 'Application mode_53',\n",
       " 'Application order_1',\n",
       " 'Application order_2',\n",
       " 'Application order_3',\n",
       " 'Application order_4',\n",
       " 'Application order_5',\n",
       " 'Application order_6',\n",
       " 'Application order_9',\n",
       " 'Course_39',\n",
       " 'Course_171',\n",
       " 'Course_979',\n",
       " 'Course_8014',\n",
       " 'Course_9003',\n",
       " 'Course_9070',\n",
       " 'Course_9085',\n",
       " 'Course_9119',\n",
       " 'Course_9130',\n",
       " 'Course_9147',\n",
       " 'Course_9238',\n",
       " 'Course_9254',\n",
       " 'Course_9500',\n",
       " 'Course_9556',\n",
       " 'Course_9670',\n",
       " 'Course_9773',\n",
       " 'Course_9853',\n",
       " 'Course_9991',\n",
       " 'Daytime/evening attendance_1',\n",
       " 'Previous qualification_2',\n",
       " 'Previous qualification_3',\n",
       " 'Previous qualification_4',\n",
       " 'Previous qualification_5',\n",
       " 'Previous qualification_6',\n",
       " 'Previous qualification_9',\n",
       " 'Previous qualification_10',\n",
       " 'Previous qualification_11',\n",
       " 'Previous qualification_12',\n",
       " 'Previous qualification_14',\n",
       " 'Previous qualification_15',\n",
       " 'Previous qualification_17',\n",
       " 'Previous qualification_19',\n",
       " 'Previous qualification_36',\n",
       " 'Previous qualification_37',\n",
       " 'Previous qualification_38',\n",
       " 'Previous qualification_39',\n",
       " 'Previous qualification_40',\n",
       " 'Previous qualification_42',\n",
       " 'Previous qualification_43',\n",
       " 'Nacionality_2',\n",
       " 'Nacionality_6',\n",
       " 'Nacionality_11',\n",
       " 'Nacionality_17',\n",
       " 'Nacionality_21',\n",
       " 'Nacionality_22',\n",
       " 'Nacionality_24',\n",
       " 'Nacionality_25',\n",
       " 'Nacionality_26',\n",
       " 'Nacionality_32',\n",
       " 'Nacionality_41',\n",
       " 'Nacionality_62',\n",
       " 'Nacionality_100',\n",
       " 'Nacionality_101',\n",
       " 'Nacionality_103',\n",
       " 'Nacionality_105',\n",
       " 'Nacionality_109',\n",
       " \"Mother's qualification_2\",\n",
       " \"Mother's qualification_3\",\n",
       " \"Mother's qualification_4\",\n",
       " \"Mother's qualification_5\",\n",
       " \"Mother's qualification_6\",\n",
       " \"Mother's qualification_7\",\n",
       " \"Mother's qualification_8\",\n",
       " \"Mother's qualification_9\",\n",
       " \"Mother's qualification_10\",\n",
       " \"Mother's qualification_11\",\n",
       " \"Mother's qualification_12\",\n",
       " \"Mother's qualification_14\",\n",
       " \"Mother's qualification_15\",\n",
       " \"Mother's qualification_18\",\n",
       " \"Mother's qualification_19\",\n",
       " \"Mother's qualification_22\",\n",
       " \"Mother's qualification_26\",\n",
       " \"Mother's qualification_27\",\n",
       " \"Mother's qualification_28\",\n",
       " \"Mother's qualification_29\",\n",
       " \"Mother's qualification_30\",\n",
       " \"Mother's qualification_31\",\n",
       " \"Mother's qualification_33\",\n",
       " \"Mother's qualification_34\",\n",
       " \"Mother's qualification_35\",\n",
       " \"Mother's qualification_36\",\n",
       " \"Mother's qualification_37\",\n",
       " \"Mother's qualification_38\",\n",
       " \"Mother's qualification_39\",\n",
       " \"Mother's qualification_40\",\n",
       " \"Mother's qualification_41\",\n",
       " \"Mother's qualification_42\",\n",
       " \"Mother's qualification_43\",\n",
       " \"Mother's qualification_44\",\n",
       " \"Father's qualification_2\",\n",
       " \"Father's qualification_3\",\n",
       " \"Father's qualification_4\",\n",
       " \"Father's qualification_5\",\n",
       " \"Father's qualification_6\",\n",
       " \"Father's qualification_7\",\n",
       " \"Father's qualification_9\",\n",
       " \"Father's qualification_10\",\n",
       " \"Father's qualification_11\",\n",
       " \"Father's qualification_12\",\n",
       " \"Father's qualification_13\",\n",
       " \"Father's qualification_14\",\n",
       " \"Father's qualification_15\",\n",
       " \"Father's qualification_18\",\n",
       " \"Father's qualification_19\",\n",
       " \"Father's qualification_20\",\n",
       " \"Father's qualification_21\",\n",
       " \"Father's qualification_22\",\n",
       " \"Father's qualification_23\",\n",
       " \"Father's qualification_24\",\n",
       " \"Father's qualification_25\",\n",
       " \"Father's qualification_26\",\n",
       " \"Father's qualification_27\",\n",
       " \"Father's qualification_29\",\n",
       " \"Father's qualification_30\",\n",
       " \"Father's qualification_31\",\n",
       " \"Father's qualification_33\",\n",
       " \"Father's qualification_34\",\n",
       " \"Father's qualification_35\",\n",
       " \"Father's qualification_36\",\n",
       " \"Father's qualification_37\",\n",
       " \"Father's qualification_38\",\n",
       " \"Father's qualification_39\",\n",
       " \"Father's qualification_40\",\n",
       " \"Father's qualification_41\",\n",
       " \"Father's qualification_42\",\n",
       " \"Father's qualification_43\",\n",
       " \"Father's qualification_44\",\n",
       " \"Mother's occupation_1\",\n",
       " \"Mother's occupation_2\",\n",
       " \"Mother's occupation_3\",\n",
       " \"Mother's occupation_4\",\n",
       " \"Mother's occupation_5\",\n",
       " \"Mother's occupation_6\",\n",
       " \"Mother's occupation_7\",\n",
       " \"Mother's occupation_8\",\n",
       " \"Mother's occupation_9\",\n",
       " \"Mother's occupation_10\",\n",
       " \"Mother's occupation_11\",\n",
       " \"Mother's occupation_38\",\n",
       " \"Mother's occupation_90\",\n",
       " \"Mother's occupation_99\",\n",
       " \"Mother's occupation_101\",\n",
       " \"Mother's occupation_103\",\n",
       " \"Mother's occupation_122\",\n",
       " \"Mother's occupation_123\",\n",
       " \"Mother's occupation_124\",\n",
       " \"Mother's occupation_125\",\n",
       " \"Mother's occupation_127\",\n",
       " \"Mother's occupation_131\",\n",
       " \"Mother's occupation_132\",\n",
       " \"Mother's occupation_134\",\n",
       " \"Mother's occupation_141\",\n",
       " \"Mother's occupation_143\",\n",
       " \"Mother's occupation_144\",\n",
       " \"Mother's occupation_151\",\n",
       " \"Mother's occupation_152\",\n",
       " \"Mother's occupation_153\",\n",
       " \"Mother's occupation_163\",\n",
       " \"Mother's occupation_171\",\n",
       " \"Mother's occupation_172\",\n",
       " \"Mother's occupation_173\",\n",
       " \"Mother's occupation_175\",\n",
       " \"Mother's occupation_191\",\n",
       " \"Mother's occupation_192\",\n",
       " \"Mother's occupation_193\",\n",
       " \"Mother's occupation_194\",\n",
       " \"Father's occupation_1\",\n",
       " \"Father's occupation_2\",\n",
       " \"Father's occupation_3\",\n",
       " \"Father's occupation_4\",\n",
       " \"Father's occupation_5\",\n",
       " \"Father's occupation_6\",\n",
       " \"Father's occupation_7\",\n",
       " \"Father's occupation_8\",\n",
       " \"Father's occupation_9\",\n",
       " \"Father's occupation_10\",\n",
       " \"Father's occupation_11\",\n",
       " \"Father's occupation_12\",\n",
       " \"Father's occupation_13\",\n",
       " \"Father's occupation_19\",\n",
       " \"Father's occupation_22\",\n",
       " \"Father's occupation_39\",\n",
       " \"Father's occupation_90\",\n",
       " \"Father's occupation_96\",\n",
       " \"Father's occupation_99\",\n",
       " \"Father's occupation_101\",\n",
       " \"Father's occupation_102\",\n",
       " \"Father's occupation_103\",\n",
       " \"Father's occupation_112\",\n",
       " \"Father's occupation_114\",\n",
       " \"Father's occupation_121\",\n",
       " \"Father's occupation_122\",\n",
       " \"Father's occupation_123\",\n",
       " \"Father's occupation_124\",\n",
       " \"Father's occupation_125\",\n",
       " \"Father's occupation_131\",\n",
       " \"Father's occupation_132\",\n",
       " \"Father's occupation_134\",\n",
       " \"Father's occupation_135\",\n",
       " \"Father's occupation_141\",\n",
       " \"Father's occupation_143\",\n",
       " \"Father's occupation_144\",\n",
       " \"Father's occupation_148\",\n",
       " \"Father's occupation_151\",\n",
       " \"Father's occupation_152\",\n",
       " \"Father's occupation_153\",\n",
       " \"Father's occupation_154\",\n",
       " \"Father's occupation_161\",\n",
       " \"Father's occupation_163\",\n",
       " \"Father's occupation_171\",\n",
       " \"Father's occupation_172\",\n",
       " \"Father's occupation_174\",\n",
       " \"Father's occupation_175\",\n",
       " \"Father's occupation_181\",\n",
       " \"Father's occupation_182\",\n",
       " \"Father's occupation_183\",\n",
       " \"Father's occupation_191\",\n",
       " \"Father's occupation_192\",\n",
       " \"Father's occupation_193\",\n",
       " \"Father's occupation_194\",\n",
       " \"Father's occupation_195\",\n",
       " 'Displaced_1',\n",
       " 'Educational special needs_1',\n",
       " 'Debtor_1',\n",
       " 'Tuition fees up to date_1',\n",
       " 'Gender_1',\n",
       " 'Scholarship holder_1',\n",
       " 'International_1',\n",
       " 'Previous qualification (grade)',\n",
       " 'Admission grade',\n",
       " 'Age at enrollment',\n",
       " 'Curricular units 1st sem (credited)',\n",
       " 'Curricular units 1st sem (enrolled)',\n",
       " 'Curricular units 1st sem (evaluations)',\n",
       " 'Curricular units 1st sem (approved)',\n",
       " 'Curricular units 1st sem (grade)',\n",
       " 'Curricular units 1st sem (without evaluations)',\n",
       " 'Curricular units 2nd sem (credited)',\n",
       " 'Curricular units 2nd sem (enrolled)',\n",
       " 'Curricular units 2nd sem (evaluations)',\n",
       " 'Curricular units 2nd sem (approved)',\n",
       " 'Curricular units 2nd sem (grade)',\n",
       " 'Curricular units 2nd sem (without evaluations)',\n",
       " 'Unemployment rate',\n",
       " 'Inflation rate',\n",
       " 'GDP']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status_2</th>\n",
       "      <th>Marital status_3</th>\n",
       "      <th>Marital status_4</th>\n",
       "      <th>Marital status_5</th>\n",
       "      <th>Marital status_6</th>\n",
       "      <th>Application mode_2</th>\n",
       "      <th>Application mode_3</th>\n",
       "      <th>Application mode_4</th>\n",
       "      <th>Application mode_5</th>\n",
       "      <th>Application mode_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 1st sem (without evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>-0.066933</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.505317</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.158418</td>\n",
       "      <td>-0.449110</td>\n",
       "      <td>0.933176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.504003</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.158418</td>\n",
       "      <td>-0.449110</td>\n",
       "      <td>0.933176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>-2.065210</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>1.763675</td>\n",
       "      <td>-0.663578</td>\n",
       "      <td>-0.372698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>1.270048</td>\n",
       "      <td>1.074940</td>\n",
       "      <td>1.079288</td>\n",
       "      <td>0.575895</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.158418</td>\n",
       "      <td>-0.449110</td>\n",
       "      <td>0.933176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.655484</td>\n",
       "      <td>1.360408</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.596330</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-1.477502</td>\n",
       "      <td>0.980680</td>\n",
       "      <td>0.178079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status_2  Marital status_3  Marital status_4  Marital status_5  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   Marital status_6  Application mode_2  Application mode_3  \\\n",
       "0               0.0                 0.0                 0.0   \n",
       "1               0.0                 0.0                 0.0   \n",
       "2               0.0                 0.0                 0.0   \n",
       "3               0.0                 0.0                 0.0   \n",
       "4               0.0                 0.0                 0.0   \n",
       "\n",
       "   Application mode_4  Application mode_5  Application mode_7  ...  \\\n",
       "0                 0.0                 0.0                 0.0  ...   \n",
       "1                 0.0                 0.0                 0.0  ...   \n",
       "2                 0.0                 0.0                 0.0  ...   \n",
       "3                 0.0                 0.0                 0.0  ...   \n",
       "4                 0.0                 0.0                 0.0  ...   \n",
       "\n",
       "   Curricular units 1st sem (without evaluations)  \\\n",
       "0                                        -0.14189   \n",
       "1                                        -0.14189   \n",
       "2                                        -0.14189   \n",
       "3                                        -0.14189   \n",
       "4                                        -0.14189   \n",
       "\n",
       "   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       "0                            -0.146765                             0.040921   \n",
       "1                            -0.146765                             0.040921   \n",
       "2                            -0.146765                             0.040921   \n",
       "3                            -0.146765                             1.270048   \n",
       "4                            -0.146765                             0.655484   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                               -0.066933   \n",
       "1                                0.504003   \n",
       "2                               -2.065210   \n",
       "3                                1.074940   \n",
       "4                                1.360408   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                             0.718660                          0.505317   \n",
       "1                            -1.445110                         -1.735681   \n",
       "2                            -1.445110                         -1.735681   \n",
       "3                             1.079288                          0.575895   \n",
       "4                             0.718660                          0.596330   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                       -0.135127          -0.158418   \n",
       "1                                       -0.135127          -0.158418   \n",
       "2                                       -0.135127           1.763675   \n",
       "3                                       -0.135127          -0.158418   \n",
       "4                                       -0.135127          -1.477502   \n",
       "\n",
       "   Inflation rate       GDP  \n",
       "0       -0.449110  0.933176  \n",
       "1       -0.449110  0.933176  \n",
       "2       -0.663578 -0.372698  \n",
       "3       -0.449110  0.933176  \n",
       "4        0.980680  0.178079  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m      3\u001b[0m         n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      4\u001b[0m         max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m27\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m     10\u001b[0m selector \u001b[38;5;241m=\u001b[39m RFECV(clf, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39mmake_scorer(accuracy_score))\n\u001b[0;32m---> 11\u001b[0m selector \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_rfe.py:726\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    723\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    724\u001b[0m     func \u001b[38;5;241m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[0;32m--> 726\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n\u001b[1;32m    732\u001b[0m scores_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_rfe.py:727\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    723\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    724\u001b[0m     func \u001b[38;5;241m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m    726\u001b[0m scores \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m--> 727\u001b[0m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrfe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    729\u001b[0m )\n\u001b[1;32m    731\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n\u001b[1;32m    732\u001b[0m scores_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_rfe.py:32\u001b[0m, in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     30\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[1;32m     31\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mscores_\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/feature_selection/_rfe.py:297\u001b[0m, in \u001b[0;36mRFE._fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[0;32m--> 297\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[1;32m    300\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[1;32m    301\u001b[0m     estimator,\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[1;32m    303\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    931\u001b[0m \n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# values from Optuna\n",
    "clf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=27,\n",
    "        min_samples_split=7,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "selector = RFECV(clf, step=1, cv=5, scoring=make_scorer(accuracy_score))\n",
    "selector = selector.fit(X_trans, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    n_estimators = trial.suggest_int('n_estimators', 10, 100)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 32)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    \n",
    "    # Create a RandomForestClassifier with the suggested hyperparameters\n",
    "    clf = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    acc = [] \n",
    "\n",
    "    # Train the model\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_trans)):\n",
    "        print(f'Kfold: {i}')\n",
    "        clf.fit(X_trans.iloc[train_index], y[train_index])\n",
    "        y_pred = clf.predict(X_trans.iloc[test_index])\n",
    "        acc.append(accuracy_score(y[test_index], y_pred))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(acc)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a study object and specify the direction of optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optimize the objective function\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy\n",
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best accuracy:', study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values from Optuna\n",
    "clf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=27,\n",
    "        min_samples_split=7,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "y_pred = clf.fit(X_trans, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = clf.feature_importances_\n",
    "feature_names_in = clf.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features by feature importances\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.23717479212021048, 'Curricular units 2nd sem (approved)'),\n",
       " (0.19276256641696565, 'Curricular units 1st sem (approved)'),\n",
       " (0.07755956505143712, 'Curricular units 2nd sem (evaluations)'),\n",
       " (0.07021640297460942, 'Curricular units 1st sem (evaluations)'),\n",
       " (0.045342037571617554, 'Tuition fees up to date_1'),\n",
       " (0.03892187160865344, 'Age at enrollment'),\n",
       " (0.03528718817274194, 'Scholarship holder_1'),\n",
       " (0.021239497960192456, 'Curricular units 2nd sem (enrolled)'),\n",
       " (0.01987590803899424, 'Application mode_39'),\n",
       " (0.019235818366483356, 'Curricular units 1st sem (enrolled)'),\n",
       " (0.017216875127898122, 'Gender_1'),\n",
       " (0.01607705430687772, 'Debtor_1'),\n",
       " (0.007577871458403177, 'Course_9500'),\n",
       " (0.006045119947070335, 'Course_9147'),\n",
       " (0.006031297610314499, 'Course_9853'),\n",
       " (0.005565968173254438, \"Mother's qualification_34\"),\n",
       " (0.005239125664491659, 'Displaced_1'),\n",
       " (0.0047465140524226, 'Application order_1'),\n",
       " (0.0045412770880508225, 'Course_9119'),\n",
       " (0.004322581222427299, \"Father's qualification_19\"),\n",
       " (0.0042838292648568815, \"Mother's occupation_9\"),\n",
       " (0.004282411589925769, \"Father's qualification_38\"),\n",
       " (0.004278146655255458, 'Application mode_17'),\n",
       " (0.004214273559916955, \"Father's occupation_9\"),\n",
       " (0.004181755221112333, \"Mother's qualification_19\"),\n",
       " (0.004124278769288971, \"Father's qualification_37\"),\n",
       " (0.00410631381132754, \"Mother's qualification_37\"),\n",
       " (0.0038368614029154692, 'Course_171'),\n",
       " (0.0037854078029781195, \"Father's occupation_7\"),\n",
       " (0.0036423816096355383, \"Mother's occupation_4\")]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Top 20 features by feature importances')\n",
    "most_important_features = sorted(zip(feature_importances, feature_names_in), reverse=True)[0:30]\n",
    "most_important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Importance', ylabel='Feature'>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(most_important_features, columns=['Importance', 'Feature'])\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the first 12 seem relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 1st sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 1st sem (evaluations)</th>\n",
       "      <th>Tuition fees up to date_1</th>\n",
       "      <th>Age at enrollment</th>\n",
       "      <th>Scholarship holder_1</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Application mode_39</th>\n",
       "      <th>Curricular units 1st sem (enrolled)</th>\n",
       "      <th>Gender_1</th>\n",
       "      <th>Debtor_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.677640</td>\n",
       "      <td>-0.066933</td>\n",
       "      <td>-0.385478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.621067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-0.066414</td>\n",
       "      <td>0.504003</td>\n",
       "      <td>0.184603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.621067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.554522</td>\n",
       "      <td>-2.065210</td>\n",
       "      <td>-2.095724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.621067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.079288</td>\n",
       "      <td>1.049667</td>\n",
       "      <td>1.074940</td>\n",
       "      <td>0.469644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.621067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.270048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.677640</td>\n",
       "      <td>1.360408</td>\n",
       "      <td>1.324767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.621067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76513</th>\n",
       "      <td>0.358031</td>\n",
       "      <td>0.677640</td>\n",
       "      <td>0.218535</td>\n",
       "      <td>0.469644</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.621067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76514</th>\n",
       "      <td>0.718660</td>\n",
       "      <td>-0.066414</td>\n",
       "      <td>0.504003</td>\n",
       "      <td>4.175176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.475912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76515</th>\n",
       "      <td>0.358031</td>\n",
       "      <td>-0.066414</td>\n",
       "      <td>0.218535</td>\n",
       "      <td>1.609808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.475912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.573642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.533278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76516</th>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.554522</td>\n",
       "      <td>-2.065210</td>\n",
       "      <td>-2.095724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.621067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76517</th>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.677640</td>\n",
       "      <td>-0.352401</td>\n",
       "      <td>-0.385478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.475912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76518 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Curricular units 2nd sem (approved)  \\\n",
       "0                                 0.718660   \n",
       "1                                -1.445110   \n",
       "2                                -1.445110   \n",
       "3                                 1.079288   \n",
       "4                                 0.718660   \n",
       "...                                    ...   \n",
       "76513                             0.358031   \n",
       "76514                             0.718660   \n",
       "76515                             0.358031   \n",
       "76516                            -1.445110   \n",
       "76517                             0.718660   \n",
       "\n",
       "       Curricular units 1st sem (approved)  \\\n",
       "0                                 0.677640   \n",
       "1                                -0.066414   \n",
       "2                                -1.554522   \n",
       "3                                 1.049667   \n",
       "4                                 0.677640   \n",
       "...                                    ...   \n",
       "76513                             0.677640   \n",
       "76514                            -0.066414   \n",
       "76515                            -0.066414   \n",
       "76516                            -1.554522   \n",
       "76517                             0.677640   \n",
       "\n",
       "       Curricular units 2nd sem (evaluations)  \\\n",
       "0                                   -0.066933   \n",
       "1                                    0.504003   \n",
       "2                                   -2.065210   \n",
       "3                                    1.074940   \n",
       "4                                    1.360408   \n",
       "...                                       ...   \n",
       "76513                                0.218535   \n",
       "76514                                0.504003   \n",
       "76515                                0.218535   \n",
       "76516                               -2.065210   \n",
       "76517                               -0.352401   \n",
       "\n",
       "       Curricular units 1st sem (evaluations)  Tuition fees up to date_1  \\\n",
       "0                                   -0.385478                        1.0   \n",
       "1                                    0.184603                        1.0   \n",
       "2                                   -2.095724                        1.0   \n",
       "3                                    0.469644                        1.0   \n",
       "4                                    1.324767                        1.0   \n",
       "...                                       ...                        ...   \n",
       "76513                                0.469644                        1.0   \n",
       "76514                                4.175176                        1.0   \n",
       "76515                                1.609808                        1.0   \n",
       "76516                               -2.095724                        1.0   \n",
       "76517                               -0.385478                        1.0   \n",
       "\n",
       "       Age at enrollment  Scholarship holder_1  \\\n",
       "0              -0.621067                   1.0   \n",
       "1              -0.621067                   0.0   \n",
       "2              -0.621067                   0.0   \n",
       "3              -0.621067                   1.0   \n",
       "4              -0.621067                   0.0   \n",
       "...                  ...                   ...   \n",
       "76513          -0.621067                   1.0   \n",
       "76514          -0.475912                   0.0   \n",
       "76515          -0.475912                   0.0   \n",
       "76516          -0.621067                   0.0   \n",
       "76517          -0.475912                   0.0   \n",
       "\n",
       "       Curricular units 2nd sem (enrolled)  Application mode_39  \\\n",
       "0                                 0.040921                  0.0   \n",
       "1                                 0.040921                  0.0   \n",
       "2                                 0.040921                  0.0   \n",
       "3                                 1.270048                  0.0   \n",
       "4                                 0.655484                  0.0   \n",
       "...                                    ...                  ...   \n",
       "76513                             0.040921                  0.0   \n",
       "76514                             0.040921                  0.0   \n",
       "76515                            -0.573642                  0.0   \n",
       "76516                             0.040921                  0.0   \n",
       "76517                             0.040921                  0.0   \n",
       "\n",
       "       Curricular units 1st sem (enrolled)  Gender_1  Debtor_1  \n",
       "0                                 0.064892       0.0       0.0  \n",
       "1                                 0.064892       0.0       0.0  \n",
       "2                                 0.064892       1.0       0.0  \n",
       "3                                 0.663062       0.0       0.0  \n",
       "4                                 0.663062       0.0       0.0  \n",
       "...                                    ...       ...       ...  \n",
       "76513                             0.064892       0.0       0.0  \n",
       "76514                             0.064892       0.0       0.0  \n",
       "76515                            -0.533278       0.0       0.0  \n",
       "76516                             0.064892       0.0       0.0  \n",
       "76517                             0.064892       0.0       0.0  \n",
       "\n",
       "[76518 rows x 12 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans[feature_importances[0:12]['Feature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold: 0\n",
      "Kfold: 1\n",
      "Kfold: 2\n",
      "Kfold: 3\n",
      "Kfold: 4\n"
     ]
    }
   ],
   "source": [
    "X_reduced = X_trans[feature_importances[0:12]['Feature']]\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=27,\n",
    "        min_samples_split=7,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "acc = [] \n",
    "\n",
    "# Train the model\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X_reduced)):\n",
    "    print(f'Kfold: {i}')\n",
    "    clf.fit(X_reduced.iloc[train_index], y[train_index])\n",
    "    y_pred = clf.predict(X_reduced.iloc[test_index])\n",
    "    acc.append(accuracy_score(y[test_index], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8137692782479743"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status_2</th>\n",
       "      <th>Marital status_3</th>\n",
       "      <th>Marital status_4</th>\n",
       "      <th>Marital status_5</th>\n",
       "      <th>Marital status_6</th>\n",
       "      <th>Application mode_2</th>\n",
       "      <th>Application mode_3</th>\n",
       "      <th>Application mode_4</th>\n",
       "      <th>Application mode_5</th>\n",
       "      <th>Application mode_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>-0.066933</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.505317</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.158418</td>\n",
       "      <td>-0.449110</td>\n",
       "      <td>0.933176</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.504003</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.158418</td>\n",
       "      <td>-0.449110</td>\n",
       "      <td>0.933176</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>-2.065210</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>1.763675</td>\n",
       "      <td>-0.663578</td>\n",
       "      <td>-0.372698</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>1.270048</td>\n",
       "      <td>1.074940</td>\n",
       "      <td>1.079288</td>\n",
       "      <td>0.575895</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.158418</td>\n",
       "      <td>-0.449110</td>\n",
       "      <td>0.933176</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.655484</td>\n",
       "      <td>1.360408</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.596330</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-1.477502</td>\n",
       "      <td>0.980680</td>\n",
       "      <td>0.178079</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status_2  Marital status_3  Marital status_4  Marital status_5  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   Marital status_6  Application mode_2  Application mode_3  \\\n",
       "0               0.0                 0.0                 0.0   \n",
       "1               0.0                 0.0                 0.0   \n",
       "2               0.0                 0.0                 0.0   \n",
       "3               0.0                 0.0                 0.0   \n",
       "4               0.0                 0.0                 0.0   \n",
       "\n",
       "   Application mode_4  Application mode_5  Application mode_7  ...  \\\n",
       "0                 0.0                 0.0                 0.0  ...   \n",
       "1                 0.0                 0.0                 0.0  ...   \n",
       "2                 0.0                 0.0                 0.0  ...   \n",
       "3                 0.0                 0.0                 0.0  ...   \n",
       "4                 0.0                 0.0                 0.0  ...   \n",
       "\n",
       "   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       "0                            -0.146765                             0.040921   \n",
       "1                            -0.146765                             0.040921   \n",
       "2                            -0.146765                             0.040921   \n",
       "3                            -0.146765                             1.270048   \n",
       "4                            -0.146765                             0.655484   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                               -0.066933   \n",
       "1                                0.504003   \n",
       "2                               -2.065210   \n",
       "3                                1.074940   \n",
       "4                                1.360408   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                             0.718660                          0.505317   \n",
       "1                            -1.445110                         -1.735681   \n",
       "2                            -1.445110                         -1.735681   \n",
       "3                             1.079288                          0.575895   \n",
       "4                             0.718660                          0.596330   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                       -0.135127          -0.158418   \n",
       "1                                       -0.135127          -0.158418   \n",
       "2                                       -0.135127           1.763675   \n",
       "3                                       -0.135127          -0.158418   \n",
       "4                                       -0.135127          -1.477502   \n",
       "\n",
       "   Inflation rate       GDP         y  \n",
       "0       -0.449110  0.933176  Graduate  \n",
       "1       -0.449110  0.933176   Dropout  \n",
       "2       -0.663578 -0.372698   Dropout  \n",
       "3       -0.449110  0.933176  Enrolled  \n",
       "4        0.980680  0.178079  Graduate  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_autogluon = X_trans\n",
    "df_autogluon['y'] = y\n",
    "df_autogluon = TabularDataset(df_autogluon)\n",
    "df_autogluon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240611_144058\"\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 3600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240611_144058/ds_sub_fit/sub_fit_ho.\n",
      "2024-06-11 11:41:02,128\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "E0611 11:41:21.126419000   20422 socket_utils_common_posix.cc:224]     check for SO_REUSEPORT: UNKNOWN:Protocol not available {created_time:\"2024-06-11T11:41:21.125525262-03:00\", errno:92, os_error:\"Protocol not available\", syscall:\"getsockopt(SO_REUSEPORT)\"}\n",
      "Running the sub-fit in a ray process to avoid memory leakage.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 82f2de7146e0fa1b606e7c3481c7b205964ee9ebffffffff Worker ID: 3e6a05cb3716fc606a65d4378a1f9b332c9cf9b1ce5d56553e046f17 Node ID: 556efccc4406bb270da1876ca393c887e20f057d4c083661c59a5a28 Worker IP address: 192.168.0.112 Worker port: 57353 Worker PID: 20026 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned. RPC Error message: Socket closed; RPC Error details: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Spend 985 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 2615 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 2615s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240611_144058\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.0\n",
      "Python Version:     3.8.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #4355-Microsoft Thu Apr 12 17:37:00 PST 2024\n",
      "CPU Count:          8\n",
      "Memory Avail:       1.27 GB / 7.77 GB (16.3%)\n",
      "Disk Space Avail:   147.03 GB / 237.83 GB (61.8%)\n",
      "===================================================\n",
      "Train Data Rows:    76518\n",
      "Train Data Columns: 280\n",
      "Label Column:       y\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 3\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1173.83 MB\n",
      "\tTrain Data (Original)  Memory Usage: 23.86 MB (2.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 262 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 120): ['Application mode_3', 'Application mode_4', 'Application mode_12', 'Application mode_26', 'Application mode_35', 'Application order_9', 'Course_39', 'Course_979', 'Previous qualification_4', 'Previous qualification_5', 'Previous qualification_11', 'Previous qualification_15', 'Previous qualification_17', 'Previous qualification_36', 'Previous qualification_37', 'Nacionality_2', 'Nacionality_6', 'Nacionality_11', 'Nacionality_17', 'Nacionality_21', 'Nacionality_22', 'Nacionality_24', 'Nacionality_25', 'Nacionality_32', 'Nacionality_62', 'Nacionality_100', 'Nacionality_101', 'Nacionality_103', 'Nacionality_105', 'Nacionality_109', \"Mother's qualification_5\", \"Mother's qualification_7\", \"Mother's qualification_8\", \"Mother's qualification_10\", \"Mother's qualification_15\", \"Mother's qualification_18\", \"Mother's qualification_22\", \"Mother's qualification_26\", \"Mother's qualification_27\", \"Mother's qualification_28\", \"Mother's qualification_30\", \"Mother's qualification_31\", \"Mother's qualification_33\", \"Mother's qualification_36\", \"Mother's qualification_43\", \"Mother's qualification_44\", \"Father's qualification_6\", \"Father's qualification_7\", \"Father's qualification_13\", \"Father's qualification_14\", \"Father's qualification_15\", \"Father's qualification_18\", \"Father's qualification_20\", \"Father's qualification_22\", \"Father's qualification_23\", \"Father's qualification_24\", \"Father's qualification_25\", \"Father's qualification_26\", \"Father's qualification_27\", \"Father's qualification_30\", \"Father's qualification_31\", \"Father's qualification_33\", \"Father's qualification_35\", \"Father's qualification_41\", \"Father's qualification_42\", \"Father's qualification_43\", \"Father's qualification_44\", \"Mother's occupation_11\", \"Mother's occupation_38\", \"Mother's occupation_101\", \"Mother's occupation_103\", \"Mother's occupation_122\", \"Mother's occupation_124\", \"Mother's occupation_125\", \"Mother's occupation_127\", \"Mother's occupation_131\", \"Mother's occupation_134\", \"Mother's occupation_143\", \"Mother's occupation_144\", \"Mother's occupation_152\", \"Mother's occupation_153\", \"Mother's occupation_163\", \"Mother's occupation_171\", \"Mother's occupation_172\", \"Mother's occupation_175\", \"Father's occupation_11\", \"Father's occupation_12\", \"Father's occupation_13\", \"Father's occupation_19\", \"Father's occupation_22\", \"Father's occupation_39\", \"Father's occupation_96\", \"Father's occupation_101\", \"Father's occupation_102\", \"Father's occupation_103\", \"Father's occupation_112\", \"Father's occupation_121\", \"Father's occupation_122\", \"Father's occupation_123\", \"Father's occupation_124\", \"Father's occupation_125\", \"Father's occupation_131\", \"Father's occupation_132\", \"Father's occupation_134\", \"Father's occupation_135\", \"Father's occupation_141\", \"Father's occupation_143\", \"Father's occupation_148\", \"Father's occupation_151\", \"Father's occupation_152\", \"Father's occupation_153\", \"Father's occupation_161\", \"Father's occupation_163\", \"Father's occupation_172\", \"Father's occupation_174\", \"Father's occupation_181\", \"Father's occupation_182\", \"Father's occupation_191\", \"Father's occupation_194\", \"Father's occupation_195\"]\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', ['sparse']) : 120 | ['Application mode_3', 'Application mode_4', 'Application mode_12', 'Application mode_26', 'Application mode_35', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', ['sparse']) : 160 | ['Marital status_2', 'Marital status_3', 'Marital status_4', 'Marital status_5', 'Marital status_6', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', ['sparse']) :  18 | ['Previous qualification (grade)', 'Admission grade', 'Age at enrollment', 'Curricular units 1st sem (credited)', 'Curricular units 1st sem (enrolled)', ...]\n",
      "\t\t('int', ['bool'])     : 142 | ['Marital status_2', 'Marital status_3', 'Marital status_4', 'Marital status_5', 'Marital status_6', ...]\n",
      "\t9.1s = Fit runtime\n",
      "\t160 features in original data used to generate 160 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 26.12 MB (2.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 10.36s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1735.99s of the 2604.62s of remaining time.\n",
      "\tWarning: Potentially not enough memory to safely train model. Estimated to require 0.176 GB out of 1.031 GB available memory (17.106%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo avoid this warning, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.19 to avoid the warning)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\t0.7757\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t14.89s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1718.77s of the 2587.4s of remaining time.\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 0.176 GB out of 0.753 GB available memory (23.403%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=1.22 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1718.14s of the 2586.77s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 37.29% memory usage per fold, 74.58%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=37.29%)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=22969, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 264, in _fit\n",
      "    data = self._preprocess_train(X, y, X_val, y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 116, in _preprocess_train\n",
      "    X = self.preprocess(X, fit=True)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 401, in preprocess\n",
      "    X = self._preprocess(X, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 154, in _preprocess\n",
      "    self._cont_normalization = (np.array(X[self.cont_columns].mean()), np.array(X[self.cont_columns].std()))\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11424, in std\n",
      "    return NDFrame.std(self, axis, skipna, ddof, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11137, in std\n",
      "    return self._stat_function_ddof(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11101, in _stat_function_ddof\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10519, in _reduce\n",
      "    res = df._mgr.reduce(blk_func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 1534, in reduce\n",
      "    nbs = blk.reduce(func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 339, in reduce\n",
      "    result = func(self.values)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10480, in blk_func\n",
      "    return values._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform std with type Sparse[float64, 0]\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=22969, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 264, in _fit\n",
      "    data = self._preprocess_train(X, y, X_val, y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 116, in _preprocess_train\n",
      "    X = self.preprocess(X, fit=True)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 401, in preprocess\n",
      "    X = self._preprocess(X, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 154, in _preprocess\n",
      "    self._cont_normalization = (np.array(X[self.cont_columns].mean()), np.array(X[self.cont_columns].std()))\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11424, in std\n",
      "    return NDFrame.std(self, axis, skipna, ddof, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11137, in std\n",
      "    return self._stat_function_ddof(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11101, in _stat_function_ddof\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10519, in _reduce\n",
      "    res = df._mgr.reduce(blk_func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 1534, in reduce\n",
      "    nbs = blk.reduce(func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 339, in reduce\n",
      "    result = func(self.values)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10480, in blk_func\n",
      "    return values._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform std with type Sparse[float64, 0]\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1699.95s of the 2568.58s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 22.33% memory usage per fold, 44.66%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=22.33%)\n",
      "2024-06-11 11:58:15,099\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8318\t = Validation score   (accuracy)\n",
      "\t86.42s\t = Training   runtime\n",
      "\t3.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1606.32s of the 2474.95s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.24% memory usage per fold, 60.96%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=15.24%)\n",
      "\t0.8328\t = Validation score   (accuracy)\n",
      "\t48.1s\t = Training   runtime\n",
      "\t3.71s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1550.87s of the 2419.5s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 78 due to low memory. Expected memory usage reduced from 57.41% -> 15.0% of available memory...\n",
      "\t0.8206\t = Validation score   (accuracy)\n",
      "\t10.91s\t = Training   runtime\n",
      "\t2.4s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1536.58s of the 2405.21s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 48 due to low memory. Expected memory usage reduced from 92.84% -> 15.0% of available memory...\n",
      "\t0.8167\t = Validation score   (accuracy)\n",
      "\t6.37s\t = Training   runtime\n",
      "\t1.74s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1527.87s of the 2396.5s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 32.09% memory usage per fold, 64.17%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=32.09%)\n",
      "\t0.8318\t = Validation score   (accuracy)\n",
      "\t180.77s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1341.67s of the 2210.3s of remaining time.\n",
      "\tWarning: Model is expected to require 121.15% of available memory...\n",
      "\tNot enough memory to train ExtraTreesGini_BAG_L1... Skipping this model.\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1335.47s of the 2204.1s of remaining time.\n",
      "\tWarning: Model is expected to require 134.95% of available memory...\n",
      "\tNot enough memory to train ExtraTreesEntr_BAG_L1... Skipping this model.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1333.83s of the 2202.46s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 37.66% memory usage per fold, 75.32%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=37.66%)\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tTask was killed due to the node running low on memory.\n",
      "\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.\n",
      "\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1321.84s of the 2190.47s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 22.37% memory usage per fold, 44.73%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=22.37%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=25065, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=25065, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1307.68s of the 2176.31s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.67% memory usage per fold, 49.35%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=24.67%)\n",
      "2024-06-11 12:04:47,100\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8336\t = Validation score   (accuracy)\n",
      "\t114.89s\t = Training   runtime\n",
      "\t4.77s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1188.45s of the 2057.08s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.61% memory usage per fold, 49.23%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=24.61%)\n",
      "\t0.8335\t = Validation score   (accuracy)\n",
      "\t246.39s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 936.9s of the 1805.53s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.24% memory usage per fold, 52.97%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=13.24%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=26448, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=26448, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 917.06s of the 1785.69s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.79% memory usage per fold, 63.16%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=15.79%)\n",
      "2024-06-11 12:11:14,027\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-06-11 12:11:14,032\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-06-11 12:11:14,035\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8327\t = Validation score   (accuracy)\n",
      "\t124.85s\t = Training   runtime\n",
      "\t21.56s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 783.26s of the 1651.89s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 22.64% memory usage per fold, 45.28%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=22.64%)\n",
      "\tWarning: Exception caused NeuralNetFastAI_r191_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=27082, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 264, in _fit\n",
      "    data = self._preprocess_train(X, y, X_val, y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 116, in _preprocess_train\n",
      "    X = self.preprocess(X, fit=True)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 401, in preprocess\n",
      "    X = self._preprocess(X, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 154, in _preprocess\n",
      "    self._cont_normalization = (np.array(X[self.cont_columns].mean()), np.array(X[self.cont_columns].std()))\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11424, in std\n",
      "    return NDFrame.std(self, axis, skipna, ddof, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11137, in std\n",
      "    return self._stat_function_ddof(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11101, in _stat_function_ddof\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10519, in _reduce\n",
      "    res = df._mgr.reduce(blk_func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 1534, in reduce\n",
      "    nbs = blk.reduce(func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 339, in reduce\n",
      "    result = func(self.values)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10480, in blk_func\n",
      "    return values._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform std with type Sparse[float64, 0]\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=27082, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 264, in _fit\n",
      "    data = self._preprocess_train(X, y, X_val, y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 116, in _preprocess_train\n",
      "    X = self.preprocess(X, fit=True)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 401, in preprocess\n",
      "    X = self._preprocess(X, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 154, in _preprocess\n",
      "    self._cont_normalization = (np.array(X[self.cont_columns].mean()), np.array(X[self.cont_columns].std()))\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11424, in std\n",
      "    return NDFrame.std(self, axis, skipna, ddof, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11137, in std\n",
      "    return self._stat_function_ddof(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11101, in _stat_function_ddof\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10519, in _reduce\n",
      "    res = df._mgr.reduce(blk_func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 1534, in reduce\n",
      "    nbs = blk.reduce(func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 339, in reduce\n",
      "    result = func(self.values)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10480, in blk_func\n",
      "    return values._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform std with type Sparse[float64, 0]\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 766.25s of the 1634.88s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 29.23% memory usage per fold, 58.46%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=29.23%)\n",
      "2024-06-11 12:13:46,808\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=27083, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 264, in _fit\n",
      "    data = self._preprocess_train(X, y, X_val, y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 116, in _preprocess_train\n",
      "    X = self.preprocess(X, fit=True)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 401, in preprocess\n",
      "    X = self._preprocess(X, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 154, in _preprocess\n",
      "    self._cont_normalization = (np.array(X[self.cont_columns].mean()), np.array(X[self.cont_columns].std()))\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11424, in std\n",
      "    return NDFrame.std(self, axis, skipna, ddof, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11137, in std\n",
      "    return self._stat_function_ddof(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11101, in _stat_function_ddof\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10519, in _reduce\n",
      "    res = df._mgr.reduce(blk_func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 1534, in reduce\n",
      "    nbs = blk.reduce(func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 339, in reduce\n",
      "    result = func(self.values)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10480, in blk_func\n",
      "    return values._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform std with type Sparse[float64, 0]\n",
      "\t0.8303\t = Validation score   (accuracy)\n",
      "\t512.64s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 250.17s of the 1118.8s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.46% memory usage per fold, 65.83%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=16.46%)\n",
      "\t0.8297\t = Validation score   (accuracy)\n",
      "\t163.9s\t = Training   runtime\n",
      "\t33.27s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 73.01s of the 941.64s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.20% memory usage per fold, 52.79%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=13.20%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r22_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=28487, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=28487, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 51.13s of the 919.76s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 1 folds in parallel instead (Estimated 41.06% memory usage per fold, 41.06%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=41.06%)\n",
      "\t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n",
      "\t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n",
      "2024-06-11 12:25:39,982\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-06-11 12:25:39,987\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-06-11 12:25:39,988\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8258\t = Validation score   (accuracy)\n",
      "\t78.33s\t = Training   runtime\n",
      "\t0.81s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 837.77s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMLarge_BAG_L1': 1.0}\n",
      "\t0.8336\t = Validation score   (accuracy)\n",
      "\t4.46s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 833.25s of the 833.01s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 31.09% memory usage per fold, 62.18%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=31.09%)\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=29709, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 264, in _fit\n",
      "    data = self._preprocess_train(X, y, X_val, y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 116, in _preprocess_train\n",
      "    X = self.preprocess(X, fit=True)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 401, in preprocess\n",
      "    X = self._preprocess(X, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 154, in _preprocess\n",
      "    self._cont_normalization = (np.array(X[self.cont_columns].mean()), np.array(X[self.cont_columns].std()))\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11424, in std\n",
      "    return NDFrame.std(self, axis, skipna, ddof, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11137, in std\n",
      "    return self._stat_function_ddof(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11101, in _stat_function_ddof\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10519, in _reduce\n",
      "    res = df._mgr.reduce(blk_func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 1534, in reduce\n",
      "    nbs = blk.reduce(func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 339, in reduce\n",
      "    result = func(self.values)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10480, in blk_func\n",
      "    return values._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform std with type Sparse[float64, 0]\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=29709, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 264, in _fit\n",
      "    data = self._preprocess_train(X, y, X_val, y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 116, in _preprocess_train\n",
      "    X = self.preprocess(X, fit=True)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 401, in preprocess\n",
      "    X = self._preprocess(X, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 154, in _preprocess\n",
      "    self._cont_normalization = (np.array(X[self.cont_columns].mean()), np.array(X[self.cont_columns].std()))\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11424, in std\n",
      "    return NDFrame.std(self, axis, skipna, ddof, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11137, in std\n",
      "    return self._stat_function_ddof(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11101, in _stat_function_ddof\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10519, in _reduce\n",
      "    res = df._mgr.reduce(blk_func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 1534, in reduce\n",
      "    nbs = blk.reduce(func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 339, in reduce\n",
      "    result = func(self.values)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10480, in blk_func\n",
      "    return values._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform std with type Sparse[float64, 0]\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 816.72s of the 816.44s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.32% memory usage per fold, 48.63%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=24.32%)\n",
      "2024-06-11 12:27:27,165\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.8338\t = Validation score   (accuracy)\n",
      "\t59.31s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 750.89s of the 750.61s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.94% memory usage per fold, 71.76%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=17.94%)\n",
      "\t0.834\t = Validation score   (accuracy)\n",
      "\t41.96s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 703.08s of the 702.83s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 186 due to low memory. Expected memory usage reduced from 24.08% -> 15.0% of available memory...\n",
      "\t0.8308\t = Validation score   (accuracy)\n",
      "\t37.57s\t = Training   runtime\n",
      "\t6.86s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 657.47s of the 657.24s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 144 due to low memory. Expected memory usage reduced from 31.14% -> 15.0% of available memory...\n",
      "\t0.8301\t = Validation score   (accuracy)\n",
      "\t29.03s\t = Training   runtime\n",
      "\t5.44s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 621.02s of the 620.79s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 27.51% memory usage per fold, 55.03%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=27.51%)\n",
      "\t0.8331\t = Validation score   (accuracy)\n",
      "\t62.89s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 552.66s of the 552.41s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 97 due to low memory. Expected memory usage reduced from 45.93% -> 15.0% of available memory...\n",
      "\t0.8292\t = Validation score   (accuracy)\n",
      "\t14.1s\t = Training   runtime\n",
      "\t2.84s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 534.98s of the 534.75s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 86 due to low memory. Expected memory usage reduced from 52.22% -> 15.0% of available memory...\n",
      "\t0.8286\t = Validation score   (accuracy)\n",
      "\t11.78s\t = Training   runtime\n",
      "\t2.91s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 519.67s of the 519.43s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 35.14% memory usage per fold, 70.28%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=35.14%)\n",
      "\t0.8338\t = Validation score   (accuracy)\n",
      "\t90.52s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 424.06s of the 423.77s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.38% memory usage per fold, 57.54%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=14.38%)\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=31986, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=31986, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "2024-06-11 12:34:19,553\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=31989, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "2024-06-11 12:34:19,559\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=31987, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "2024-06-11 12:34:19,581\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 399.65s of the 399.37s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 33.57% memory usage per fold, 67.13%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=33.57%)\n",
      "\t0.8332\t = Validation score   (accuracy)\n",
      "\t99.16s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 295.74s of the 295.48s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 23.99% memory usage per fold, 47.97%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=23.99%)\n",
      "\t0.8333\t = Validation score   (accuracy)\n",
      "\t65.36s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 225.32s of the 225.08s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.58% memory usage per fold, 70.31%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=17.58%)\n",
      "\tWarning: Exception caused NeuralNetTorch_r79_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=489, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=489, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 185, in _fit\n",
      "    train_dataset, val_dataset = self._generate_datasets(X=X, y=y, params=processor_kwargs, X_val=X_val, y_val=y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 457, in _generate_datasets\n",
      "    train_dataset = self._process_train_data(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 512, in _process_train_data\n",
      "    self._types_of_features, df = self._get_types_of_features(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_nn_model.py\", line 58, in _get_types_of_features\n",
      "    if np.abs(feature_data.skew()) > skew_threshold:\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11577, in skew\n",
      "    return NDFrame.skew(self, axis, skipna, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11223, in skew\n",
      "    return self._stat_function(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11158, in _stat_function\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/series.py\", line 4656, in _reduce\n",
      "    return delegate._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform skew with type Sparse[float64, 0]\n",
      "Fitting model: LightGBM_r131_BAG_L2 ... Training model for up to 207.62s of the 207.36s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 45afc463ed38f34855bb7b7c9b6748c2eddf64bf01000000 Worker ID: 0a54b097ae9aa9a473c82f8b7118c06f7459e9f09609743b870884cc Node ID: 556efccc4406bb270da1876ca393c887e20f057d4c083661c59a5a28 Worker IP address: 192.168.0.112 Worker port: 60034 Worker PID: 491 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned. RPC Error message: Socket closed; RPC Error details: \n",
      "\u001b[33m(raylet)\u001b[0m A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: 720dd86924b2eac9e35d1d748b426c65383a509901000000 Worker ID: 4c96cb99ce7909ca9df5e0d48336a0051f521733bfc736c322516ce9 Node ID: 556efccc4406bb270da1876ca393c887e20f057d4c083661c59a5a28 Worker IP address: 192.168.0.112 Worker port: 60055 Worker PID: 677 Worker exit type: SYSTEM_ERROR Worker exit detail: The leased worker has unrecoverable failure. Worker is requested to be destroyed when it is returned. RPC Error message: Socket closed; RPC Error details: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 19.71% memory usage per fold, 78.82%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=19.71%)\n",
      "2024-06-11 12:37:34,064\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-06-11 12:37:34,066\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-06-11 12:37:34,069\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t0.7887\t = Validation score   (accuracy)\n",
      "\t84.08s\t = Training   runtime\n",
      "\t2.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L2 ... Training model for up to 118.76s of the 118.52s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 22.33% memory usage per fold, 44.65%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=22.33%)\n",
      "\tWarning: Exception caused NeuralNetFastAI_r191_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=1158, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 264, in _fit\n",
      "    data = self._preprocess_train(X, y, X_val, y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 116, in _preprocess_train\n",
      "    X = self.preprocess(X, fit=True)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 401, in preprocess\n",
      "    X = self._preprocess(X, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 154, in _preprocess\n",
      "    self._cont_normalization = (np.array(X[self.cont_columns].mean()), np.array(X[self.cont_columns].std()))\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11424, in std\n",
      "    return NDFrame.std(self, axis, skipna, ddof, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11137, in std\n",
      "    return self._stat_function_ddof(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11101, in _stat_function_ddof\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10519, in _reduce\n",
      "    res = df._mgr.reduce(blk_func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 1534, in reduce\n",
      "    nbs = blk.reduce(func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 339, in reduce\n",
      "    result = func(self.values)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10480, in blk_func\n",
      "    return values._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform std with type Sparse[float64, 0]\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 286, in _fit\n",
      "    self._fit_folds(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 717, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 663, in after_all_folds_scheduled\n",
      "    self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 605, in _run_parallel\n",
      "    self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 568, in _process_fold_results\n",
      "    raise processed_exception\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 534, in _process_fold_results\n",
      "    fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time = self.ray.get(finished)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TypeError): \u001b[36mray::_ray_fit()\u001b[39m (pid=1158, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 264, in _fit\n",
      "    data = self._preprocess_train(X, y, X_val, y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 116, in _preprocess_train\n",
      "    X = self.preprocess(X, fit=True)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 401, in preprocess\n",
      "    X = self._preprocess(X, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 154, in _preprocess\n",
      "    self._cont_normalization = (np.array(X[self.cont_columns].mean()), np.array(X[self.cont_columns].std()))\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11424, in std\n",
      "    return NDFrame.std(self, axis, skipna, ddof, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11137, in std\n",
      "    return self._stat_function_ddof(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11101, in _stat_function_ddof\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10519, in _reduce\n",
      "    res = df._mgr.reduce(blk_func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 1534, in reduce\n",
      "    nbs = blk.reduce(func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 339, in reduce\n",
      "    result = func(self.values)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10480, in blk_func\n",
      "    return values._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform std with type Sparse[float64, 0]\n",
      "Fitting model: CatBoost_r9_BAG_L2 ... Training model for up to 105.18s of the 104.92s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 1 folds in parallel instead (Estimated 59.15% memory usage per fold, 59.15%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1 workers, per: cpus=4, gpus=0, memory=59.15%)\n",
      "\t\tSwitching to pseudo sequential ParallelFoldFittingStrategy to avoid Python memory leakage.\n",
      "\t\tOverrule this behavior by setting fold_fitting_strategy to 'sequential_local' in ag_args_ensemble when when calling `predictor.fit`\n",
      "2024-06-11 12:39:19,274\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=1157, ip=192.168.0.112)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 404, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 855, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 264, in _fit\n",
      "    data = self._preprocess_train(X, y, X_val, y_val)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 116, in _preprocess_train\n",
      "    X = self.preprocess(X, fit=True)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 401, in preprocess\n",
      "    X = self._preprocess(X, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/autogluon/tabular/models/fastainn/tabular_nn_fastai.py\", line 154, in _preprocess\n",
      "    self._cont_normalization = (np.array(X[self.cont_columns].mean()), np.array(X[self.cont_columns].std()))\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11424, in std\n",
      "    return NDFrame.std(self, axis, skipna, ddof, numeric_only, **kwargs)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11137, in std\n",
      "    return self._stat_function_ddof(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/generic.py\", line 11101, in _stat_function_ddof\n",
      "    return self._reduce(\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10519, in _reduce\n",
      "    res = df._mgr.reduce(blk_func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\", line 1534, in reduce\n",
      "    nbs = blk.reduce(func)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\", line 339, in reduce\n",
      "    result = func(self.values)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/frame.py\", line 10480, in blk_func\n",
      "    return values._reduce(name, skipna=skipna, **kwds)\n",
      "  File \"/home/estacio/.local/lib/python3.8/site-packages/pandas/core/arrays/sparse/array.py\", line 1377, in _reduce\n",
      "    raise TypeError(f\"cannot perform {name} with type {self.dtype}\")\n",
      "TypeError: cannot perform std with type Sparse[float64, 0]\n",
      "\t0.8335\t = Validation score   (accuracy)\n",
      "\t108.1s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -11.65s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 1.0}\n",
      "\t0.834\t = Validation score   (accuracy)\n",
      "\t5.02s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2631.76s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240611_144058\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='y', eval_metric='accuracy').fit(df_autogluon, presets='best_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.833961</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>88.641282</td>\n",
       "      <td>1615.655832</td>\n",
       "      <td>0.717303</td>\n",
       "      <td>41.963669</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.833961</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>88.650506</td>\n",
       "      <td>1620.674526</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>5.018693</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>0.833843</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>88.862845</td>\n",
       "      <td>1664.207210</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>90.515046</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.833765</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>88.522727</td>\n",
       "      <td>1633.000926</td>\n",
       "      <td>0.598748</td>\n",
       "      <td>59.308763</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.833556</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>4.772610</td>\n",
       "      <td>114.889032</td>\n",
       "      <td>4.772610</td>\n",
       "      <td>114.889032</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.833556</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>4.783207</td>\n",
       "      <td>119.350974</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>4.461942</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost_r9_BAG_L2</td>\n",
       "      <td>0.833477</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>88.184140</td>\n",
       "      <td>1681.791422</td>\n",
       "      <td>0.260161</td>\n",
       "      <td>108.099259</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CatBoost_r177_BAG_L1</td>\n",
       "      <td>0.833451</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.382942</td>\n",
       "      <td>246.386862</td>\n",
       "      <td>0.382942</td>\n",
       "      <td>246.386862</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoost_r177_BAG_L2</td>\n",
       "      <td>0.833268</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>88.151143</td>\n",
       "      <td>1639.048842</td>\n",
       "      <td>0.227164</td>\n",
       "      <td>65.356678</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.833163</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>88.693076</td>\n",
       "      <td>1672.854667</td>\n",
       "      <td>0.769097</td>\n",
       "      <td>99.162503</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>0.833072</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>88.398880</td>\n",
       "      <td>1636.586570</td>\n",
       "      <td>0.474900</td>\n",
       "      <td>62.894406</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.832824</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>3.705512</td>\n",
       "      <td>48.103971</td>\n",
       "      <td>3.705512</td>\n",
       "      <td>48.103971</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM_r131_BAG_L1</td>\n",
       "      <td>0.832667</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>21.563755</td>\n",
       "      <td>124.845794</td>\n",
       "      <td>21.563755</td>\n",
       "      <td>124.845794</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.831843</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.448798</td>\n",
       "      <td>180.773801</td>\n",
       "      <td>0.448798</td>\n",
       "      <td>180.773801</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.831817</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>3.203509</td>\n",
       "      <td>86.422209</td>\n",
       "      <td>3.203509</td>\n",
       "      <td>86.422209</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestGini_BAG_L2</td>\n",
       "      <td>0.830785</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>94.785771</td>\n",
       "      <td>1611.261729</td>\n",
       "      <td>6.861791</td>\n",
       "      <td>37.569565</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CatBoost_r9_BAG_L1</td>\n",
       "      <td>0.830275</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.742363</td>\n",
       "      <td>512.641047</td>\n",
       "      <td>0.742363</td>\n",
       "      <td>512.641047</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestEntr_BAG_L2</td>\n",
       "      <td>0.830145</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>93.367086</td>\n",
       "      <td>1602.719409</td>\n",
       "      <td>5.443107</td>\n",
       "      <td>29.027245</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LightGBM_r96_BAG_L1</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>33.267455</td>\n",
       "      <td>163.897542</td>\n",
       "      <td>33.267455</td>\n",
       "      <td>163.897542</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.829217</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>90.760614</td>\n",
       "      <td>1587.794230</td>\n",
       "      <td>2.836635</td>\n",
       "      <td>14.102067</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.828642</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>90.832403</td>\n",
       "      <td>1585.471672</td>\n",
       "      <td>2.908423</td>\n",
       "      <td>11.779508</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBoost_r33_BAG_L1</td>\n",
       "      <td>0.825753</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.812261</td>\n",
       "      <td>78.333772</td>\n",
       "      <td>0.812261</td>\n",
       "      <td>78.333772</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.820604</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>2.396326</td>\n",
       "      <td>10.909267</td>\n",
       "      <td>2.396326</td>\n",
       "      <td>10.909267</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.816697</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.739742</td>\n",
       "      <td>6.371551</td>\n",
       "      <td>1.739742</td>\n",
       "      <td>6.371551</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LightGBM_r131_BAG_L2</td>\n",
       "      <td>0.788743</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>90.435149</td>\n",
       "      <td>1657.770874</td>\n",
       "      <td>2.511170</td>\n",
       "      <td>84.078711</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.775700</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>14.888707</td>\n",
       "      <td>0.117315</td>\n",
       "      <td>14.888707</td>\n",
       "      <td>0.117315</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val eval_metric  pred_time_val  \\\n",
       "0           LightGBM_BAG_L2   0.833961    accuracy      88.641282   \n",
       "1       WeightedEnsemble_L3   0.833961    accuracy      88.650506   \n",
       "2            XGBoost_BAG_L2   0.833843    accuracy      88.862845   \n",
       "3         LightGBMXT_BAG_L2   0.833765    accuracy      88.522727   \n",
       "4      LightGBMLarge_BAG_L1   0.833556    accuracy       4.772610   \n",
       "5       WeightedEnsemble_L2   0.833556    accuracy       4.783207   \n",
       "6        CatBoost_r9_BAG_L2   0.833477    accuracy      88.184140   \n",
       "7      CatBoost_r177_BAG_L1   0.833451    accuracy       0.382942   \n",
       "8      CatBoost_r177_BAG_L2   0.833268    accuracy      88.151143   \n",
       "9      LightGBMLarge_BAG_L2   0.833163    accuracy      88.693076   \n",
       "10          CatBoost_BAG_L2   0.833072    accuracy      88.398880   \n",
       "11          LightGBM_BAG_L1   0.832824    accuracy       3.705512   \n",
       "12     LightGBM_r131_BAG_L1   0.832667    accuracy      21.563755   \n",
       "13          CatBoost_BAG_L1   0.831843    accuracy       0.448798   \n",
       "14        LightGBMXT_BAG_L1   0.831817    accuracy       3.203509   \n",
       "15  RandomForestGini_BAG_L2   0.830785    accuracy      94.785771   \n",
       "16       CatBoost_r9_BAG_L1   0.830275    accuracy       0.742363   \n",
       "17  RandomForestEntr_BAG_L2   0.830145    accuracy      93.367086   \n",
       "18      LightGBM_r96_BAG_L1   0.829700    accuracy      33.267455   \n",
       "19    ExtraTreesGini_BAG_L2   0.829217    accuracy      90.760614   \n",
       "20    ExtraTreesEntr_BAG_L2   0.828642    accuracy      90.832403   \n",
       "21       XGBoost_r33_BAG_L1   0.825753    accuracy       0.812261   \n",
       "22  RandomForestGini_BAG_L1   0.820604    accuracy       2.396326   \n",
       "23  RandomForestEntr_BAG_L1   0.816697    accuracy       1.739742   \n",
       "24     LightGBM_r131_BAG_L2   0.788743    accuracy      90.435149   \n",
       "25    KNeighborsUnif_BAG_L1   0.775700    accuracy      14.888707   \n",
       "\n",
       "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   1615.655832                0.717303          41.963669            2   \n",
       "1   1620.674526                0.009224           5.018693            3   \n",
       "2   1664.207210                0.938865          90.515046            2   \n",
       "3   1633.000926                0.598748          59.308763            2   \n",
       "4    114.889032                4.772610         114.889032            1   \n",
       "5    119.350974                0.010597           4.461942            2   \n",
       "6   1681.791422                0.260161         108.099259            2   \n",
       "7    246.386862                0.382942         246.386862            1   \n",
       "8   1639.048842                0.227164          65.356678            2   \n",
       "9   1672.854667                0.769097          99.162503            2   \n",
       "10  1636.586570                0.474900          62.894406            2   \n",
       "11    48.103971                3.705512          48.103971            1   \n",
       "12   124.845794               21.563755         124.845794            1   \n",
       "13   180.773801                0.448798         180.773801            1   \n",
       "14    86.422209                3.203509          86.422209            1   \n",
       "15  1611.261729                6.861791          37.569565            2   \n",
       "16   512.641047                0.742363         512.641047            1   \n",
       "17  1602.719409                5.443107          29.027245            2   \n",
       "18   163.897542               33.267455         163.897542            1   \n",
       "19  1587.794230                2.836635          14.102067            2   \n",
       "20  1585.471672                2.908423          11.779508            2   \n",
       "21    78.333772                0.812261          78.333772            1   \n",
       "22    10.909267                2.396326          10.909267            1   \n",
       "23     6.371551                1.739742           6.371551            1   \n",
       "24  1657.770874                2.511170          84.078711            2   \n",
       "25     0.117315               14.888707           0.117315            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         15  \n",
       "1        True         26  \n",
       "2        True         21  \n",
       "3        True         14  \n",
       "4        True          7  \n",
       "5        True         13  \n",
       "6        True         25  \n",
       "7        True          8  \n",
       "8        True         23  \n",
       "9        True         22  \n",
       "10       True         18  \n",
       "11       True          3  \n",
       "12       True          9  \n",
       "13       True          6  \n",
       "14       True          2  \n",
       "15       True         16  \n",
       "16       True         10  \n",
       "17       True         17  \n",
       "18       True         11  \n",
       "19       True         19  \n",
       "20       True         20  \n",
       "21       True         12  \n",
       "22       True          4  \n",
       "23       True          5  \n",
       "24       True         24  \n",
       "25       True          1  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./datasets/test.csv')\n",
    "df_test = df_test.astype('category')\n",
    "df_test = df_test.astype({'Previous qualification (grade)': 'float64',\n",
    "           'Admission grade': 'float64',\n",
    "           'Age at enrollment': 'int64',\n",
    "           'Curricular units 1st sem (credited)': 'int64',\n",
    "           'Curricular units 1st sem (enrolled)': 'int64',\n",
    "           'Curricular units 1st sem (evaluations)': 'int64',\n",
    "           'Curricular units 1st sem (approved)': 'int64',\n",
    "           'Curricular units 1st sem (grade)': 'float64',\n",
    "           'Curricular units 1st sem (without evaluations)': 'int64',\n",
    "           'Curricular units 2nd sem (credited)': 'int64',\n",
    "           'Curricular units 2nd sem (enrolled)': 'int64',\n",
    "           'Curricular units 2nd sem (evaluations)': 'int64',\n",
    "           'Curricular units 2nd sem (approved)': 'int64',\n",
    "           'Curricular units 2nd sem (grade)': 'float64',\n",
    "           'Curricular units 2nd sem (without evaluations)': 'int64',\n",
    "           'Unemployment rate': 'float64',\n",
    "           'Inflation rate': 'float64',\n",
    "           'GDP': 'float64'\n",
    "           })\n",
    "id = df_test.pop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./datasets/test.csv')\n",
    "df_test = df_test.astype('category')\n",
    "df_test = df_test.astype({'Previous qualification (grade)': 'float64',\n",
    "           'Admission grade': 'float64',\n",
    "           'Age at enrollment': 'int64',\n",
    "           'Curricular units 1st sem (credited)': 'int64',\n",
    "           'Curricular units 1st sem (enrolled)': 'int64',\n",
    "           'Curricular units 1st sem (evaluations)': 'int64',\n",
    "           'Curricular units 1st sem (approved)': 'int64',\n",
    "           'Curricular units 1st sem (grade)': 'float64',\n",
    "           'Curricular units 1st sem (without evaluations)': 'int64',\n",
    "           'Curricular units 2nd sem (credited)': 'int64',\n",
    "           'Curricular units 2nd sem (enrolled)': 'int64',\n",
    "           'Curricular units 2nd sem (evaluations)': 'int64',\n",
    "           'Curricular units 2nd sem (approved)': 'int64',\n",
    "           'Curricular units 2nd sem (grade)': 'float64',\n",
    "           'Curricular units 2nd sem (without evaluations)': 'int64',\n",
    "           'Unemployment rate': 'float64',\n",
    "           'Inflation rate': 'float64',\n",
    "           'GDP': 'float64'\n",
    "           })\n",
    "id = df_test.pop('id')\n",
    "\n",
    "cat_variables = df_test.select_dtypes(include='category').columns.to_list()\n",
    "num_variables = df_test.select_dtypes(include=['int64', 'float64']).columns.to_list()\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop='first'), cat_variables),\n",
    "    ('num', StandardScaler(), num_variables)\n",
    "])\n",
    "\n",
    "df_test = ct.fit_transform(df_test)\n",
    "\n",
    "col_names = ct.named_transformers_['cat'].get_feature_names_out().tolist()+ct.named_transformers_['num'].get_feature_names_out().tolist()\n",
    "df_test = pd.DataFrame.sparse.from_spmatrix(df_test, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status_2</th>\n",
       "      <th>Marital status_3</th>\n",
       "      <th>Marital status_4</th>\n",
       "      <th>Marital status_5</th>\n",
       "      <th>Marital status_6</th>\n",
       "      <th>Application mode_2</th>\n",
       "      <th>Application mode_3</th>\n",
       "      <th>Application mode_5</th>\n",
       "      <th>Application mode_7</th>\n",
       "      <th>Application mode_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 1st sem (without evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>1.285135</td>\n",
       "      <td>-2.118802</td>\n",
       "      <td>-1.469064</td>\n",
       "      <td>-1.766338</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>0.897514</td>\n",
       "      <td>-1.089794</td>\n",
       "      <td>0.389264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>-0.371118</td>\n",
       "      <td>0.712878</td>\n",
       "      <td>0.689656</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>-0.158656</td>\n",
       "      <td>-0.448201</td>\n",
       "      <td>0.935535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>1.085285</td>\n",
       "      <td>0.349221</td>\n",
       "      <td>0.234843</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>1.501040</td>\n",
       "      <td>1.120136</td>\n",
       "      <td>-1.764733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>3.272438</td>\n",
       "      <td>1.285135</td>\n",
       "      <td>1.959127</td>\n",
       "      <td>0.349221</td>\n",
       "      <td>0.234843</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>-0.988505</td>\n",
       "      <td>0.122103</td>\n",
       "      <td>1.597278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>0.502724</td>\n",
       "      <td>-0.014436</td>\n",
       "      <td>0.174201</td>\n",
       "      <td>4.144503</td>\n",
       "      <td>-1.478870</td>\n",
       "      <td>0.977560</td>\n",
       "      <td>0.180526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status_2  Marital status_3  Marital status_4  Marital status_5  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   Marital status_6  Application mode_2  Application mode_3  \\\n",
       "0               0.0                 0.0                 0.0   \n",
       "1               0.0                 0.0                 0.0   \n",
       "2               0.0                 0.0                 0.0   \n",
       "3               0.0                 0.0                 0.0   \n",
       "4               0.0                 0.0                 0.0   \n",
       "\n",
       "   Application mode_5  Application mode_7  Application mode_10  ...  \\\n",
       "0                 0.0                 0.0                  0.0  ...   \n",
       "1                 0.0                 0.0                  0.0  ...   \n",
       "2                 0.0                 0.0                  0.0  ...   \n",
       "3                 0.0                 0.0                  0.0  ...   \n",
       "4                 0.0                 0.0                  0.0  ...   \n",
       "\n",
       "   Curricular units 1st sem (without evaluations)  \\\n",
       "0                                       -0.143296   \n",
       "1                                       -0.143296   \n",
       "2                                       -0.143296   \n",
       "3                                       -0.143296   \n",
       "4                                       -0.143296   \n",
       "\n",
       "   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       "0                            -0.147375                             1.285135   \n",
       "1                            -0.147375                             0.034924   \n",
       "2                            -0.147375                             0.034924   \n",
       "3                             3.272438                             1.285135   \n",
       "4                            -0.147375                             0.034924   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                               -2.118802   \n",
       "1                               -0.371118   \n",
       "2                                1.085285   \n",
       "3                                1.959127   \n",
       "4                                0.502724   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                            -1.469064                         -1.766338   \n",
       "1                             0.712878                          0.689656   \n",
       "2                             0.349221                          0.234843   \n",
       "3                             0.349221                          0.234843   \n",
       "4                            -0.014436                          0.174201   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                       -0.136585           0.897514   \n",
       "1                                       -0.136585          -0.158656   \n",
       "2                                       -0.136585           1.501040   \n",
       "3                                       -0.136585          -0.988505   \n",
       "4                                        4.144503          -1.478870   \n",
       "\n",
       "   Inflation rate       GDP  \n",
       "0       -1.089794  0.389264  \n",
       "1       -0.448201  0.935535  \n",
       "2        1.120136 -1.764733  \n",
       "3        0.122103  1.597278  \n",
       "4        0.977560  0.180526  \n",
       "\n",
       "[5 rows x 264 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status_2</th>\n",
       "      <th>Marital status_3</th>\n",
       "      <th>Marital status_4</th>\n",
       "      <th>Marital status_5</th>\n",
       "      <th>Marital status_6</th>\n",
       "      <th>Application mode_2</th>\n",
       "      <th>Application mode_3</th>\n",
       "      <th>Application mode_4</th>\n",
       "      <th>Application mode_5</th>\n",
       "      <th>Application mode_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>-0.066933</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.505317</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.158418</td>\n",
       "      <td>-0.449110</td>\n",
       "      <td>0.933176</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.504003</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.158418</td>\n",
       "      <td>-0.449110</td>\n",
       "      <td>0.933176</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>-2.065210</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>1.763675</td>\n",
       "      <td>-0.663578</td>\n",
       "      <td>-0.372698</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>1.270048</td>\n",
       "      <td>1.074940</td>\n",
       "      <td>1.079288</td>\n",
       "      <td>0.575895</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.158418</td>\n",
       "      <td>-0.449110</td>\n",
       "      <td>0.933176</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.655484</td>\n",
       "      <td>1.360408</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.596330</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-1.477502</td>\n",
       "      <td>0.980680</td>\n",
       "      <td>0.178079</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 281 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status_2  Marital status_3  Marital status_4  Marital status_5  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   Marital status_6  Application mode_2  Application mode_3  \\\n",
       "0               0.0                 0.0                 0.0   \n",
       "1               0.0                 0.0                 0.0   \n",
       "2               0.0                 0.0                 0.0   \n",
       "3               0.0                 0.0                 0.0   \n",
       "4               0.0                 0.0                 0.0   \n",
       "\n",
       "   Application mode_4  Application mode_5  Application mode_7  ...  \\\n",
       "0                 0.0                 0.0                 0.0  ...   \n",
       "1                 0.0                 0.0                 0.0  ...   \n",
       "2                 0.0                 0.0                 0.0  ...   \n",
       "3                 0.0                 0.0                 0.0  ...   \n",
       "4                 0.0                 0.0                 0.0  ...   \n",
       "\n",
       "   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       "0                            -0.146765                             0.040921   \n",
       "1                            -0.146765                             0.040921   \n",
       "2                            -0.146765                             0.040921   \n",
       "3                            -0.146765                             1.270048   \n",
       "4                            -0.146765                             0.655484   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                               -0.066933   \n",
       "1                                0.504003   \n",
       "2                               -2.065210   \n",
       "3                                1.074940   \n",
       "4                                1.360408   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                             0.718660                          0.505317   \n",
       "1                            -1.445110                         -1.735681   \n",
       "2                            -1.445110                         -1.735681   \n",
       "3                             1.079288                          0.575895   \n",
       "4                             0.718660                          0.596330   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                       -0.135127          -0.158418   \n",
       "1                                       -0.135127          -0.158418   \n",
       "2                                       -0.135127           1.763675   \n",
       "3                                       -0.135127          -0.158418   \n",
       "4                                       -0.135127          -1.477502   \n",
       "\n",
       "   Inflation rate       GDP         y  \n",
       "0       -0.449110  0.933176  Graduate  \n",
       "1       -0.449110  0.933176   Dropout  \n",
       "2       -0.663578 -0.372698   Dropout  \n",
       "3       -0.449110  0.933176  Enrolled  \n",
       "4        0.980680  0.178079  Graduate  \n",
       "\n",
       "[5 rows x 281 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status_2</th>\n",
       "      <th>Marital status_3</th>\n",
       "      <th>Marital status_4</th>\n",
       "      <th>Marital status_5</th>\n",
       "      <th>Marital status_6</th>\n",
       "      <th>Application mode_2</th>\n",
       "      <th>Application mode_3</th>\n",
       "      <th>Application mode_5</th>\n",
       "      <th>Application mode_7</th>\n",
       "      <th>Application mode_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 1st sem (without evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>1.285135</td>\n",
       "      <td>-2.118802</td>\n",
       "      <td>-1.469064</td>\n",
       "      <td>-1.766338</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>0.897514</td>\n",
       "      <td>-1.089794</td>\n",
       "      <td>0.389264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>-0.371118</td>\n",
       "      <td>0.712878</td>\n",
       "      <td>0.689656</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>-0.158656</td>\n",
       "      <td>-0.448201</td>\n",
       "      <td>0.935535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>1.085285</td>\n",
       "      <td>0.349221</td>\n",
       "      <td>0.234843</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>1.501040</td>\n",
       "      <td>1.120136</td>\n",
       "      <td>-1.764733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>3.272438</td>\n",
       "      <td>1.285135</td>\n",
       "      <td>1.959127</td>\n",
       "      <td>0.349221</td>\n",
       "      <td>0.234843</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>-0.988505</td>\n",
       "      <td>0.122103</td>\n",
       "      <td>1.597278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>0.502724</td>\n",
       "      <td>-0.014436</td>\n",
       "      <td>0.174201</td>\n",
       "      <td>4.144503</td>\n",
       "      <td>-1.478870</td>\n",
       "      <td>0.977560</td>\n",
       "      <td>0.180526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>-3.715707</td>\n",
       "      <td>-2.118802</td>\n",
       "      <td>-1.469064</td>\n",
       "      <td>-1.766338</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>1.501040</td>\n",
       "      <td>1.120136</td>\n",
       "      <td>-1.764733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51008</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>-0.590181</td>\n",
       "      <td>-0.662399</td>\n",
       "      <td>-1.469064</td>\n",
       "      <td>-1.766338</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>-0.799903</td>\n",
       "      <td>-1.446235</td>\n",
       "      <td>-1.347257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51009</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>-3.715707</td>\n",
       "      <td>-2.118802</td>\n",
       "      <td>-1.469064</td>\n",
       "      <td>-1.766338</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>1.501040</td>\n",
       "      <td>1.120136</td>\n",
       "      <td>-1.764733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51010</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>0.034924</td>\n",
       "      <td>0.502724</td>\n",
       "      <td>-0.378093</td>\n",
       "      <td>0.598693</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>-1.478870</td>\n",
       "      <td>0.977560</td>\n",
       "      <td>0.180526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51011</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143296</td>\n",
       "      <td>-0.147375</td>\n",
       "      <td>-3.715707</td>\n",
       "      <td>-2.118802</td>\n",
       "      <td>-1.469064</td>\n",
       "      <td>-1.766338</td>\n",
       "      <td>-0.136585</td>\n",
       "      <td>-1.478870</td>\n",
       "      <td>0.977560</td>\n",
       "      <td>0.180526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51012 rows × 264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Marital status_2  Marital status_3  Marital status_4  Marital status_5  \\\n",
       "0                   0.0               0.0               0.0               0.0   \n",
       "1                   0.0               0.0               0.0               0.0   \n",
       "2                   0.0               0.0               0.0               0.0   \n",
       "3                   0.0               0.0               0.0               0.0   \n",
       "4                   0.0               0.0               0.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "51007               0.0               0.0               0.0               0.0   \n",
       "51008               1.0               0.0               0.0               0.0   \n",
       "51009               0.0               0.0               0.0               0.0   \n",
       "51010               0.0               0.0               0.0               0.0   \n",
       "51011               0.0               0.0               0.0               0.0   \n",
       "\n",
       "       Marital status_6  Application mode_2  Application mode_3  \\\n",
       "0                   0.0                 0.0                 0.0   \n",
       "1                   0.0                 0.0                 0.0   \n",
       "2                   0.0                 0.0                 0.0   \n",
       "3                   0.0                 0.0                 0.0   \n",
       "4                   0.0                 0.0                 0.0   \n",
       "...                 ...                 ...                 ...   \n",
       "51007               0.0                 0.0                 0.0   \n",
       "51008               0.0                 0.0                 0.0   \n",
       "51009               0.0                 0.0                 0.0   \n",
       "51010               0.0                 0.0                 0.0   \n",
       "51011               0.0                 0.0                 0.0   \n",
       "\n",
       "       Application mode_5  Application mode_7  Application mode_10  ...  \\\n",
       "0                     0.0                 0.0                  0.0  ...   \n",
       "1                     0.0                 0.0                  0.0  ...   \n",
       "2                     0.0                 0.0                  0.0  ...   \n",
       "3                     0.0                 0.0                  0.0  ...   \n",
       "4                     0.0                 0.0                  0.0  ...   \n",
       "...                   ...                 ...                  ...  ...   \n",
       "51007                 0.0                 0.0                  0.0  ...   \n",
       "51008                 0.0                 0.0                  0.0  ...   \n",
       "51009                 0.0                 0.0                  0.0  ...   \n",
       "51010                 0.0                 0.0                  0.0  ...   \n",
       "51011                 0.0                 0.0                  0.0  ...   \n",
       "\n",
       "       Curricular units 1st sem (without evaluations)  \\\n",
       "0                                           -0.143296   \n",
       "1                                           -0.143296   \n",
       "2                                           -0.143296   \n",
       "3                                           -0.143296   \n",
       "4                                           -0.143296   \n",
       "...                                               ...   \n",
       "51007                                       -0.143296   \n",
       "51008                                       -0.143296   \n",
       "51009                                       -0.143296   \n",
       "51010                                       -0.143296   \n",
       "51011                                       -0.143296   \n",
       "\n",
       "       Curricular units 2nd sem (credited)  \\\n",
       "0                                -0.147375   \n",
       "1                                -0.147375   \n",
       "2                                -0.147375   \n",
       "3                                 3.272438   \n",
       "4                                -0.147375   \n",
       "...                                    ...   \n",
       "51007                            -0.147375   \n",
       "51008                            -0.147375   \n",
       "51009                            -0.147375   \n",
       "51010                            -0.147375   \n",
       "51011                            -0.147375   \n",
       "\n",
       "       Curricular units 2nd sem (enrolled)  \\\n",
       "0                                 1.285135   \n",
       "1                                 0.034924   \n",
       "2                                 0.034924   \n",
       "3                                 1.285135   \n",
       "4                                 0.034924   \n",
       "...                                    ...   \n",
       "51007                            -3.715707   \n",
       "51008                            -0.590181   \n",
       "51009                            -3.715707   \n",
       "51010                             0.034924   \n",
       "51011                            -3.715707   \n",
       "\n",
       "       Curricular units 2nd sem (evaluations)  \\\n",
       "0                                   -2.118802   \n",
       "1                                   -0.371118   \n",
       "2                                    1.085285   \n",
       "3                                    1.959127   \n",
       "4                                    0.502724   \n",
       "...                                       ...   \n",
       "51007                               -2.118802   \n",
       "51008                               -0.662399   \n",
       "51009                               -2.118802   \n",
       "51010                                0.502724   \n",
       "51011                               -2.118802   \n",
       "\n",
       "       Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                -1.469064                         -1.766338   \n",
       "1                                 0.712878                          0.689656   \n",
       "2                                 0.349221                          0.234843   \n",
       "3                                 0.349221                          0.234843   \n",
       "4                                -0.014436                          0.174201   \n",
       "...                                    ...                               ...   \n",
       "51007                            -1.469064                         -1.766338   \n",
       "51008                            -1.469064                         -1.766338   \n",
       "51009                            -1.469064                         -1.766338   \n",
       "51010                            -0.378093                          0.598693   \n",
       "51011                            -1.469064                         -1.766338   \n",
       "\n",
       "       Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                           -0.136585           0.897514   \n",
       "1                                           -0.136585          -0.158656   \n",
       "2                                           -0.136585           1.501040   \n",
       "3                                           -0.136585          -0.988505   \n",
       "4                                            4.144503          -1.478870   \n",
       "...                                               ...                ...   \n",
       "51007                                       -0.136585           1.501040   \n",
       "51008                                       -0.136585          -0.799903   \n",
       "51009                                       -0.136585           1.501040   \n",
       "51010                                       -0.136585          -1.478870   \n",
       "51011                                       -0.136585          -1.478870   \n",
       "\n",
       "       Inflation rate       GDP  \n",
       "0           -1.089794  0.389264  \n",
       "1           -0.448201  0.935535  \n",
       "2            1.120136 -1.764733  \n",
       "3            0.122103  1.597278  \n",
       "4            0.977560  0.180526  \n",
       "...               ...       ...  \n",
       "51007        1.120136 -1.764733  \n",
       "51008       -1.446235 -1.347257  \n",
       "51009        1.120136 -1.764733  \n",
       "51010        0.977560  0.180526  \n",
       "51011        0.977560  0.180526  \n",
       "\n",
       "[51012 rows x 264 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./datasets/test.csv')\n",
    "df_test = df_test.astype('category')\n",
    "df_test = df_test.astype({'Previous qualification (grade)': 'float64',\n",
    "           'Admission grade': 'float64',\n",
    "           'Age at enrollment': 'int64',\n",
    "           'Curricular units 1st sem (credited)': 'int64',\n",
    "           'Curricular units 1st sem (enrolled)': 'int64',\n",
    "           'Curricular units 1st sem (evaluations)': 'int64',\n",
    "           'Curricular units 1st sem (approved)': 'int64',\n",
    "           'Curricular units 1st sem (grade)': 'float64',\n",
    "           'Curricular units 1st sem (without evaluations)': 'int64',\n",
    "           'Curricular units 2nd sem (credited)': 'int64',\n",
    "           'Curricular units 2nd sem (enrolled)': 'int64',\n",
    "           'Curricular units 2nd sem (evaluations)': 'int64',\n",
    "           'Curricular units 2nd sem (approved)': 'int64',\n",
    "           'Curricular units 2nd sem (grade)': 'float64',\n",
    "           'Curricular units 2nd sem (without evaluations)': 'int64',\n",
    "           'Unemployment rate': 'float64',\n",
    "           'Inflation rate': 'float64',\n",
    "           'GDP': 'float64'\n",
    "           })\n",
    "id = df_test.pop('id')\n",
    "\n",
    "df_test = ct.transform(df_test)\n",
    "df_test = pd.DataFrame.sparse.from_spmatrix(df_test, columns=col_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status_2</th>\n",
       "      <th>Marital status_3</th>\n",
       "      <th>Marital status_4</th>\n",
       "      <th>Marital status_5</th>\n",
       "      <th>Marital status_6</th>\n",
       "      <th>Application mode_2</th>\n",
       "      <th>Application mode_3</th>\n",
       "      <th>Application mode_4</th>\n",
       "      <th>Application mode_5</th>\n",
       "      <th>Application mode_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 1st sem (without evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>1.270048</td>\n",
       "      <td>-2.065210</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>0.896848</td>\n",
       "      <td>-1.092515</td>\n",
       "      <td>0.386841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>-0.352401</td>\n",
       "      <td>0.718660</td>\n",
       "      <td>0.698506</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.158418</td>\n",
       "      <td>-0.449110</td>\n",
       "      <td>0.933176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>1.074940</td>\n",
       "      <td>0.358031</td>\n",
       "      <td>0.247731</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>1.499858</td>\n",
       "      <td>1.123659</td>\n",
       "      <td>-1.767406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>3.065833</td>\n",
       "      <td>1.270048</td>\n",
       "      <td>1.931344</td>\n",
       "      <td>0.358031</td>\n",
       "      <td>0.247731</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.987556</td>\n",
       "      <td>0.122806</td>\n",
       "      <td>1.594996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.504003</td>\n",
       "      <td>-0.002597</td>\n",
       "      <td>0.187627</td>\n",
       "      <td>4.192905</td>\n",
       "      <td>-1.477502</td>\n",
       "      <td>0.980680</td>\n",
       "      <td>0.178079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>-3.646459</td>\n",
       "      <td>-2.065210</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>1.499858</td>\n",
       "      <td>1.123659</td>\n",
       "      <td>-1.767406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51008</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>-0.573642</td>\n",
       "      <td>-0.637869</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-0.799116</td>\n",
       "      <td>-1.449963</td>\n",
       "      <td>-1.349882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51009</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>-3.646459</td>\n",
       "      <td>-2.065210</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>1.499858</td>\n",
       "      <td>1.123659</td>\n",
       "      <td>-1.767406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51010</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.504003</td>\n",
       "      <td>-0.363225</td>\n",
       "      <td>0.608351</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-1.477502</td>\n",
       "      <td>0.980680</td>\n",
       "      <td>0.178079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51011</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.14189</td>\n",
       "      <td>-0.146765</td>\n",
       "      <td>-3.646459</td>\n",
       "      <td>-2.065210</td>\n",
       "      <td>-1.445110</td>\n",
       "      <td>-1.735681</td>\n",
       "      <td>-0.135127</td>\n",
       "      <td>-1.477502</td>\n",
       "      <td>0.980680</td>\n",
       "      <td>0.178079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51012 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Marital status_2  Marital status_3  Marital status_4  Marital status_5  \\\n",
       "0                   0.0               0.0               0.0               0.0   \n",
       "1                   0.0               0.0               0.0               0.0   \n",
       "2                   0.0               0.0               0.0               0.0   \n",
       "3                   0.0               0.0               0.0               0.0   \n",
       "4                   0.0               0.0               0.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "51007               0.0               0.0               0.0               0.0   \n",
       "51008               1.0               0.0               0.0               0.0   \n",
       "51009               0.0               0.0               0.0               0.0   \n",
       "51010               0.0               0.0               0.0               0.0   \n",
       "51011               0.0               0.0               0.0               0.0   \n",
       "\n",
       "       Marital status_6  Application mode_2  Application mode_3  \\\n",
       "0                   0.0                 0.0                 0.0   \n",
       "1                   0.0                 0.0                 0.0   \n",
       "2                   0.0                 0.0                 0.0   \n",
       "3                   0.0                 0.0                 0.0   \n",
       "4                   0.0                 0.0                 0.0   \n",
       "...                 ...                 ...                 ...   \n",
       "51007               0.0                 0.0                 0.0   \n",
       "51008               0.0                 0.0                 0.0   \n",
       "51009               0.0                 0.0                 0.0   \n",
       "51010               0.0                 0.0                 0.0   \n",
       "51011               0.0                 0.0                 0.0   \n",
       "\n",
       "       Application mode_4  Application mode_5  Application mode_7  ...  \\\n",
       "0                     0.0                 0.0                 0.0  ...   \n",
       "1                     0.0                 0.0                 0.0  ...   \n",
       "2                     0.0                 0.0                 0.0  ...   \n",
       "3                     0.0                 0.0                 0.0  ...   \n",
       "4                     0.0                 0.0                 0.0  ...   \n",
       "...                   ...                 ...                 ...  ...   \n",
       "51007                 0.0                 0.0                 0.0  ...   \n",
       "51008                 0.0                 0.0                 0.0  ...   \n",
       "51009                 0.0                 0.0                 0.0  ...   \n",
       "51010                 0.0                 0.0                 0.0  ...   \n",
       "51011                 0.0                 0.0                 0.0  ...   \n",
       "\n",
       "       Curricular units 1st sem (without evaluations)  \\\n",
       "0                                            -0.14189   \n",
       "1                                            -0.14189   \n",
       "2                                            -0.14189   \n",
       "3                                            -0.14189   \n",
       "4                                            -0.14189   \n",
       "...                                               ...   \n",
       "51007                                        -0.14189   \n",
       "51008                                        -0.14189   \n",
       "51009                                        -0.14189   \n",
       "51010                                        -0.14189   \n",
       "51011                                        -0.14189   \n",
       "\n",
       "       Curricular units 2nd sem (credited)  \\\n",
       "0                                -0.146765   \n",
       "1                                -0.146765   \n",
       "2                                -0.146765   \n",
       "3                                 3.065833   \n",
       "4                                -0.146765   \n",
       "...                                    ...   \n",
       "51007                            -0.146765   \n",
       "51008                            -0.146765   \n",
       "51009                            -0.146765   \n",
       "51010                            -0.146765   \n",
       "51011                            -0.146765   \n",
       "\n",
       "       Curricular units 2nd sem (enrolled)  \\\n",
       "0                                 1.270048   \n",
       "1                                 0.040921   \n",
       "2                                 0.040921   \n",
       "3                                 1.270048   \n",
       "4                                 0.040921   \n",
       "...                                    ...   \n",
       "51007                            -3.646459   \n",
       "51008                            -0.573642   \n",
       "51009                            -3.646459   \n",
       "51010                             0.040921   \n",
       "51011                            -3.646459   \n",
       "\n",
       "       Curricular units 2nd sem (evaluations)  \\\n",
       "0                                   -2.065210   \n",
       "1                                   -0.352401   \n",
       "2                                    1.074940   \n",
       "3                                    1.931344   \n",
       "4                                    0.504003   \n",
       "...                                       ...   \n",
       "51007                               -2.065210   \n",
       "51008                               -0.637869   \n",
       "51009                               -2.065210   \n",
       "51010                                0.504003   \n",
       "51011                               -2.065210   \n",
       "\n",
       "       Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                -1.445110                         -1.735681   \n",
       "1                                 0.718660                          0.698506   \n",
       "2                                 0.358031                          0.247731   \n",
       "3                                 0.358031                          0.247731   \n",
       "4                                -0.002597                          0.187627   \n",
       "...                                    ...                               ...   \n",
       "51007                            -1.445110                         -1.735681   \n",
       "51008                            -1.445110                         -1.735681   \n",
       "51009                            -1.445110                         -1.735681   \n",
       "51010                            -0.363225                          0.608351   \n",
       "51011                            -1.445110                         -1.735681   \n",
       "\n",
       "       Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                           -0.135127           0.896848   \n",
       "1                                           -0.135127          -0.158418   \n",
       "2                                           -0.135127           1.499858   \n",
       "3                                           -0.135127          -0.987556   \n",
       "4                                            4.192905          -1.477502   \n",
       "...                                               ...                ...   \n",
       "51007                                       -0.135127           1.499858   \n",
       "51008                                       -0.135127          -0.799116   \n",
       "51009                                       -0.135127           1.499858   \n",
       "51010                                       -0.135127          -1.477502   \n",
       "51011                                       -0.135127          -1.477502   \n",
       "\n",
       "       Inflation rate       GDP  \n",
       "0           -1.092515  0.386841  \n",
       "1           -0.449110  0.933176  \n",
       "2            1.123659 -1.767406  \n",
       "3            0.122806  1.594996  \n",
       "4            0.980680  0.178079  \n",
       "...               ...       ...  \n",
       "51007        1.123659 -1.767406  \n",
       "51008       -1.449963 -1.349882  \n",
       "51009        1.123659 -1.767406  \n",
       "51010        0.980680  0.178079  \n",
       "51011        0.980680  0.178079  \n",
       "\n",
       "[51012 rows x 280 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values from Optuna\n",
    "clf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=27,\n",
    "        min_samples_split=7,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "y_pred = clf.fit(X_trans, y).predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autogluon\n",
    "df_test = TabularDataset(df_test)\n",
    "y_pred = predictor.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51012"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51012"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76518</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76519</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76520</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76521</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76522</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    Target\n",
       "0  76518   Dropout\n",
       "1  76519  Graduate\n",
       "2  76520  Graduate\n",
       "3  76521  Enrolled\n",
       "4  76522  Enrolled"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'id': id.tolist(), 'Target': y_pred.tolist()}\n",
    "submission = pd.DataFrame(data)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submissions/autogluon_model.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
